{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model1: LSTM_WORD_EMBED.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DAbbott93/Dean-Abbott--Dissertation/blob/main/model1_LSTM_WORD_EMBED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3mMUXmNxssf"
      },
      "source": [
        "# Code for training LSTM model (with word embedding layer) with HopeEDI data. Includes code to preprocess the data for input into the LSTM model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "833AbXxKyESU"
      },
      "source": [
        "First we must install dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb9LhJ2Wa7eq",
        "outputId": "4bff35dd-3223-4df6-837c-3102a8de02ba"
      },
      "source": [
        "#installing torch, torchvision and torchtext\n",
        "!pip install torch==1.6.0 torchvision==0.7.0 torchtext==0.7.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.7/dist-packages (1.6.0)\n",
            "Requirement already satisfied: torchvision==0.7.0 in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torchtext==0.7.0 in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (7.1.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from torchtext==0.7.0) (0.1.96)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.7.0) (4.62.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.7.0) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7.0) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL7l9qA99L4m"
      },
      "source": [
        "next we mount drive for saving files to"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ep7CDc1a7u-X",
        "outputId": "baee5b57-dc8e-4455-fb68-e3a4b0695541"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc3huLpw9XqW"
      },
      "source": [
        "Next we install the packages required for training the LSTM model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f4EtNExb9LE"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext import data\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import csv\n",
        "from nltk import tokenize\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, multilabel_confusion_matrix, f1_score, accuracy_score\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZhJn-TO9kVj"
      },
      "source": [
        "Ensuring reproducibilty and than GPU is being used-essential as code will not run on CPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSekJQw6b-v8"
      },
      "source": [
        "#This is to ensure we can reproduce this result\n",
        "SEED = 12345\n",
        "# check whether cuda is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#Torch\n",
        "torch.manual_seed(SEED)\n",
        "#Cuda algorithms\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0CHGg9K9pFG"
      },
      "source": [
        "defining some hyperparameter choices for our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHz7sv4tcBqz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1876fee9-8be5-4992-b4ad-509c88290b75"
      },
      "source": [
        "TEXT = data.Field(tokenize='spacy',batch_first=True,include_lengths=True)\n",
        "LABEL = data.LabelField(dtype = torch.float,batch_first=True)\n",
        "# set batch size\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 9\n",
        "dropout = 0.5\n",
        "PLOT = True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: LabelField class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy0sGfWC9tTP"
      },
      "source": [
        "The classifier class defines all the layers of the bi-directional LSTM and uses the torch embedding function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO6G7vW1cgKH"
      },
      "source": [
        "class classifier(nn.Module):\n",
        "#ALL define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers,\n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        # Constructor\n",
        "        super().__init__()\n",
        "\n",
        "        # torch embedding layer defined\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "\n",
        "        # lstm layer defined\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                            hidden_dim,\n",
        "                            num_layers=n_layers,\n",
        "                            bidirectional=bidirectional,\n",
        "                            dropout=dropout)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_dim) #This has to be *2 because it is a bidirectional RNN, the forward and backward components have to be concatenated together\n",
        "\n",
        "        # activation function is Sigmoid\n",
        "        self.act = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        #embedded = [batch size, sent_len, emb dim]\n",
        "\n",
        "        # pack_padded_sequence so that padded items in the sequence aren't passed to LSTM\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, batch_first=True)\n",
        "\n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "        #outputs are defines as:\n",
        "        # hidden = [batch size, num layers * num directions,hid dim]\n",
        "        # cell = [batch size, num layers * num directions,hid dim]\n",
        "\n",
        "        # concat the final forward and backward hidden state\n",
        "        hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
        "\n",
        "        # hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs = self.fc(hidden) \n",
        "\n",
        "        # Final activation function called\n",
        "        outputs = self.act(dense_outputs)\n",
        "\n",
        "        return outputs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQs9V0BqclZv"
      },
      "source": [
        "# define metric, called in training function to monitor perfromance\n",
        "def binary_accuracy(preds, y):\n",
        "    # round predictions to the closest integer for comparison\n",
        "    rounded_preds = torch.round(preds)\n",
        "    correct = (rounded_preds == y).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssBSb8nVcnbX"
      },
      "source": [
        "def train(model, iterator, optimizer, train_loss_vector, train_acc_vector, criterion):\n",
        "    # initialize every epoch with 0 loss and accuracy \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # set the model to training phase\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "        # resets the gradients after every batch so that they are not being accumulated\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # retrieve text and no. of words\n",
        "        text, text_lengths = batch.text\n",
        "\n",
        "        # convert to 1D tensor for comparion with true labels\n",
        "        predictions = model(text, text_lengths).squeeze()\n",
        "\n",
        "        # compute the loss between predictions and true labels\n",
        "        loss = criterion(predictions, batch.label.type(torch.float32))\n",
        "\n",
        "        # binary accuracy is calculated\n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "        # backpropage the loss and calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # update the weights with respect to the loss\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss and accuracy for each batch added together, note zeroed for every new epoch\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    train_loss_vector.append(epoch_loss)\n",
        "    train_acc_vector.append(epoch_acc)\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p6PrJmF-bGP"
      },
      "source": [
        "#f1 loss defined for evaluation procedure later\n",
        "def f1_loss(y_pred:torch.Tensor, y_true:torch.Tensor, is_training=False):\n",
        "    \n",
        "   \n",
        "    assert y_true.ndim == 1\n",
        "    assert y_pred.ndim == 1 or y_pred.ndim == 2\n",
        "    \n",
        "    if y_pred.ndim == 2:\n",
        "        y_pred = y_pred.argmax(dim=1)   \n",
        "    y_pred = torch.round(torch.sigmoid(y_pred))\n",
        "   \n",
        "    #true positives, true negatives, false positives and false negatives\n",
        "    tp = (y_true * y_pred).sum().to(torch.float32)\n",
        "    tn = ((1 - y_true) * (1 - y_pred)).sum().to(torch.float32)\n",
        "    fp = ((1 - y_true) * y_pred).sum().to(torch.float32)\n",
        "    fn = (y_true * (1 - y_pred)).sum().to(torch.float32)\n",
        "    \n",
        "    epsilon = 1e-7 \n",
        "    precision = tp / (tp + fp + epsilon)\n",
        "    recall = tp / (tp + fn + epsilon)\n",
        "    \n",
        "    f1 = 2* (precision*recall) / (precision + recall + epsilon)\n",
        "    f1.requires_grad = is_training\n",
        "    return f1, precision, recall, tp, tn, fp, fn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAeFSpBucqFu"
      },
      "source": [
        "#evaluation function defined for training procedure\n",
        "def evaluate(epoch, model, iterator, val_loss_vector, val_accuracy_vector, criterion):\n",
        "    # initialize every epoch\n",
        "    val_epoch_loss = 0\n",
        "    val_epoch_acc = 0\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    # deactivates autograd for evalutaing purposes\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            # retrieve text and no. of words\n",
        "            text, text_lengths = batch.text\n",
        "\n",
        "            # convert to 1d tensor\n",
        "            predictions = model(text, text_lengths).squeeze()\n",
        "\n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label.type(torch.float32))\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            # keep track of loss and accuracy\n",
        "            val_epoch_loss += loss.item()\n",
        "            val_epoch_acc += acc.item()\n",
        "\n",
        "        val_loss_vector.append(val_epoch_loss)\n",
        "        val_accuracy_vector.append(val_epoch_acc)\n",
        "    return val_epoch_loss / len(iterator), val_epoch_acc / len(iterator)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a2expaWOuhY",
        "outputId": "bd2a9d3e-26d9-4cb7-97e9-764d1b3a50a3"
      },
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "from pandas import DataFrame\n",
        "\n",
        "#Hope dataset is called 'dataset', it contains a training and validation set\n",
        "dataset= load_dataset(\"hope_edi\", \"english\")\n",
        "\n",
        "#training dataset is separated from the dataset and called df_train\n",
        "#we replace positive and negative labels with  0 and 1 respectively\n",
        "#this is then saved as a tsv file on google drive \n",
        "df_train=DataFrame({'text':dataset['train']['text'], 'label': dataset['train']['label']})\n",
        "print(df_train.shape)\n",
        "print(df_train['label'].value_counts())\n",
        "df_train['label'] = df_train['label'].replace([0], \"positive\")\n",
        "df_train['label'] = df_train['label'].replace([1], \"negative\")\n",
        "df_train.to_csv('/content/drive/MyDrive/Hope_Dataset/train.tsv', sep=\"\\t\",index=False)\n",
        "\n",
        "\n",
        "#Validation dataset is separted from dataset and called df_val\n",
        "#we replace positive and negative labels with  0 and 1 respectively\n",
        "#this is then saved as a tsv file on google drive \n",
        "df_val=DataFrame({'text':dataset['validation']['text'], 'label': dataset['validation']['label']}) \n",
        "df_val['label'] = df_train['label'].replace([0], \"positive\")\n",
        "df_val['label'] = df_train['label'].replace([1], \"negative\")\n",
        "df_val.to_csv('/content/drive/MyDrive/Hope_Dataset/test.tsv', sep=\"\\t\", index=False)\n",
        "\n",
        "df_val.head()\n",
        "df_train.tail()\n",
        "\n",
        "#we remove a third label '2' which is the non english category\n",
        "df_train=df_train.drop(df_train.query('label == 2').sample(frac=1).index)\n",
        "df_val=df_val.drop(df_val.query('label == 2').sample(frac=1).index)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.8.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.4)\n",
            "Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.16)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset hope_edi (/root/.cache/huggingface/datasets/hope_edi/english/1.0.0/fff5cf6e767fe3d1de7c5df863565bdce10bfe79dfb0b2ce42d320c3864497e3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(22762, 2)\n",
            "1    20778\n",
            "0     1962\n",
            "2       22\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOpaUhWkR7GF",
        "outputId": "ae1580e0-0db8-40d0-e6c5-b866f941acb0"
      },
      "source": [
        "df_val['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    2608\n",
              "positive     232\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 473
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh9ZRCC-eViM",
        "outputId": "abb7ee01-644c-40ed-e2cc-7741144a5d8c"
      },
      "source": [
        "fields = [('text', TEXT), ('label', LABEL)]\n",
        "#loading custom dataset\n",
        "training_data=data.TabularDataset(path =\"/content/drive/MyDrive/Hope_Dataset/train.tsv\",format = 'tsv',fields = fields,skip_header = True)\n",
        "##fields = [('text', TEXT), ('label', LABEL)]\n",
        "# loading custom dataset\n",
        "\n",
        "\n",
        "train_data, valid_data = training_data.split(split_ratio=0.8, random_state = random.seed(SEED))   #, random_state = random.seed(SEED)\n",
        "# train_data, valid_data = train_data.split(split_ratio=0.8, random_state=random.seed(SEED))\n",
        "\n",
        "\n",
        "\n",
        "print(len(train_data))\n",
        "print(len(valid_data))\n",
        "#print(len(test_data))\n",
        "# initialize glove embeddings\n",
        "TEXT.build_vocab(train_data, min_freq=4, vectors=\"glove.6B.100d\")   #this determines the size of the embedding vector\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "# No. of unique tokens in text\n",
        "print(\"Size of TEXT vocabulary:\", len(TEXT.vocab))\n",
        "\n",
        "# No. of unique tokens in label\n",
        "print(\"Size of LABEL vocabulary:\", len(LABEL.vocab))\n",
        "\n",
        "#Commonly used words\n",
        "print(TEXT.vocab.freqs.most_common(10))\n",
        "\n",
        "# Word dictionary\n",
        "print(TEXT.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18210\n",
            "4552\n",
            "Size of TEXT vocabulary: 5453\n",
            "Size of LABEL vocabulary: 3\n",
            "[('.', 12525), ('the', 8928), ('to', 6559), ('I', 6232), ('a', 5920), ('is', 5769), ('and', 5261), ('that', 4352), ('of', 4213), ('you', 4054)]\n",
            "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7fa16121aa10>>, {'<unk>': 0, '<pad>': 1, '.': 2, 'the': 3, 'to': 4, 'I': 5, 'a': 6, 'is': 7, 'and': 8, 'that': 9, 'of': 10, 'you': 11, '!': 12, 'it': 13, '?': 14, 'in': 15, 'are': 16, 'do': 17, 'people': 18, 'lives': 19, 'matter': 20, 'not': 21, \"'s\": 22, \"n't\": 23, 'for': 24, 'all': 25, ' ': 26, 'this': 27, 'they': 28, 'was': 29, 'with': 30, 'be': 31, 'black': 32, 'have': 33, 'so': 34, 'just': 35, 'like': 36, 'what': 37, 'on': 38, 'about': 39, '...': 40, 'but': 41, 'we': 42, 'as': 43, 'my': 44, 'she': 45, 'The': 46, 'who': 47, 'nâ€™t': 48, 'your': 49, 'â€™s': 50, 'It': 51, 'i': 52, 'white': 53, 'if': 54, 'or': 55, 'because': 56, 'say': 57, 'me': 58, 'think': 59, 'he': 60, 'her': 61, 'one': 62, 'up': 63, 'would': 64, 'there': 65, 'when': 66, 'by': 67, 'does': 68, 'no': 69, 'an': 70, 'from': 71, 'their': 72, 'at': 73, 'can': 74, 'them': 75, 'did': 76, 'know': 77, 'You': 78, 'how': 79, 'out': 80, 'will': 81, 'get': 82, 'has': 83, \"'m\": 84, 'only': 85, 'All': 86, 'more': 87, 'should': 88, 'racist': 89, 'being': 90, 'saying': 91, '-': 92, 'This': 93, 'Black': 94, 'BLM': 95, 'love': 96, 'want': 97, 'nt': 98, 'She': 99, 'That': 100, 'said': 101, 'why': 102, 'agree': 103, 'If': 104, '..': 105, 'really': 106, 'right': 107, 'life': 108, 'They': 109, 'other': 110, 'been': 111, \"'re\": 112, 'â€œ': 113, 'these': 114, 'were': 115, 'God': 116, 'even': 117, 'police': 118, 'than': 119, 'What': 120, 'now': 121, 'then': 122, 'see': 123, 'go': 124, 'way': 125, 'years': 126, 'time': 127, 'We': 128, 'his': 129, 'some': 130, 'ca': 131, 'am': 132, 'too': 133, 'us': 134, 'need': 135, 'man': 136, 'world': 137, 'much': 138, '(': 139, 'â€': 140, ')': 141, 'And': 142, 'So': 143, 'going': 144, 'Lives': 145, 'good': 146, 'girl': 147, 'mean': 148, 'Matter': 149, 'never': 150, 'same': 151, '....': 152, \"'\": 153, 'make': 154, 'person': 155, 'everyone': 156, 'race': 157, 'â€™m': 158, 'Why': 159, 'thing': 160, 'video': 161, 'racism': 162, 'down': 163, 'someone': 164, 'still': 165, 'hate': 166, 'here': 167, 'its': 168, 'Madonna': 169, 'any': 170, 'But': 171, 'had': 172, 'many': 173, 'very': 174, 'A': 175, 'our': 176, 'against': 177, 'No': 178, 'also': 179, 'believe': 180, 'women': 181, 'He': 182, 'statue': 183, '*': 184, 'u': 185, 'him': 186, 'most': 187, 'well': 188, 'movement': 189, 'where': 190, 'live': 191, 'ALL': 192, 'Do': 193, 'got': 194, 'understand': 195, 'into': 196, 'wrong': 197, 'How': 198, 'those': 199, 'something': 200, 'killed': 201, 'There': 202, 'country': 203, 'back': 204, 'always': 205, 'comment': 206, 'kids': 207, 's': 208, 'could': 209, 'look': 210, 'over': 211, 'thought': 212, 'anyone': 213, 'every': 214, 'come': 215, 'choice': 216, 'things': 217, 'Sheriff': 218, 'bad': 219, 'matters': 220, 'history': 221, 'lot': 222, 'LIVES': 223, 'homosexuality': 224, 'point': 225, 'made': 226, 'stop': 227, 'MATTER': 228, 'feel': 229, 'â€™re': 230, 'guy': 231, 'actually': 232, 'men': 233, 'ever': 234, 'better': 235, 'lol': 236, 'own': 237, 'change': 238, 'engineering': 239, 'trying': 240, 'nothing': 241, 'care': 242, 'problem': 243, 'anything': 244, 'Just': 245, 'tell': 246, 'day': 247, 'color': 248, 'm': 249, 'Because': 250, 'first': 251, 'America': 252, 'give': 253, 'support': 254, 'true': 255, 'woman': 256, 'god': 257, 'lesbian': 258, \"'ve\": 259, 'Not': 260, 'take': 261, 'before': 262, 'hope': 263, 'My': 264, 'real': 265, '  ': 266, 'THE': 267, 'which': 268, 'different': 269, 'says': 270, 'White': 271, 'ago': 272, 'George': 273, 'slave': 274, 'People': 275, 'great': 276, 'doing': 277, 'else': 278, 'means': 279, 'put': 280, 'year': 281, '+': 282, '/': 283, 'Is': 284, 'another': 285, 'through': 286, 'again': 287, 'community': 288, 'name': 289, 'When': 290, 'let': 291, 'work': 292, '\\xa0': 293, 'fact': 294, 'off': 295, 'talking': 296, 'American': 297, 'old': 298, 'stupid': 299, 'though': 300, 'around': 301, 'sheriff': 302, 'protest': 303, 'therapy': 304, 'looks': 305, 'getting': 306, 'yes': 307, 'kid': 308, 'kind': 309, 'Thank': 310, 'such': 311, 'engineer': 312, 'In': 313, 'blm': 314, 'little': 315, 'reason': 316, 'sure': 317, 'Floyd': 318, 'Juan': 319, 'called': 320, 'comments': 321, 'end': 322, 'girls': 323, 'literally': 324, 'done': 325, 'hard': 326, 'cause': 327, 'human': 328, 'read': 329, 'Clarke': 330, 'IS': 331, 'left': 332, 'Trump': 333, 'whole': 334, 'everything': 335, 'na': 336, 'cops': 337, '.....': 338, 'question': 339, 'talk': 340, 'Its': 341, 'Who': 342, 'gon': 343, 'long': 344, 'boy': 345, 'family': 346, 'group': 347, 'opinion': 348, 'sorry': 349, 'truth': 350, 'wo': 351, 'These': 352, 'skin': 353, 'straight': 354, 'came': 355, 'making': 356, 'others': 357, 'respect': 358, \"'ll\": 359, 'Jesus': 360, 'after': 361, 'conversion': 362, 'keep': 363, 'makes': 364, 'media': 365, 'part': 366, 'ppl': 367, 'yourself': 368, 'guys': 369, 'needs': 370, 'until': 371, 'away': 372, 'seems': 373, 'hair': 374, 'slavery': 375, '&': 376, '1': 377, 'As': 378, 'help': 379, 'yeah': 380, 'Oh': 381, 'religion': 382, '%': 383, 'David': 384, 'equal': 385, 'short': 386, 'word': 387, '4': 388, 'money': 389, 'Christian': 390, 'already': 391, 'seen': 392, 'Democrats': 393, 'find': 394, 'hear': 395, 'new': 396, 'sense': 397, 'stuff': 398, 'Americans': 399, 'To': 400, 'Your': 401, 'exactly': 402, 'face': 403, 'gave': 404, 'hell': 405, 'use': 406, 'coming': 407, 'next': 408, 'Yes': 409, 'ones': 410, 'religious': 411, '2020': 412, 'Africa': 413, 'Love': 414, 'issue': 415, 'past': 416, 'amazing': 417, 'course': 418, 'job': 419, 'young': 420, 'heard': 421, 'pretty': 422, 'pure': 423, 'statement': 424, 'told': 425, 'try': 426, 'war': 427, 'bible': 428, 'blacks': 429, 'since': 430, 'start': 431, 'themselves': 432, 'book': 433, 'call': 434, 'happened': 435, 'ok': 436, 'protests': 437, 'used': 438, 'Well': 439, 'child': 440, 'friends': 441, 'place': 442, 'probably': 443, 'best': 444, 'big': 445, 'equality': 446, 'female': 447, 'may': 448, 'sad': 449, 'thank': 450, '2': 451, 'disagree': 452, 'please': 453, 'show': 454, 'today': 455, 'whites': 456, 'brutality': 457, 'last': 458, 'Clark': 459, 'Where': 460, 'both': 461, 'wants': 462, 'Yeah': 463, 'far': 464, 'few': 465, 'interview': 466, 'parents': 467, 'started': 468, 'statues': 469, 'while': 470, 'wish': 471, 'gender': 472, 'important': 473, 'news': 474, 'watch': 475, 'NOT': 476, 'children': 477, 'oh': 478, 'races': 479, 'sexuality': 480, 'two': 481, 'ur': 482, '\\u200d': 483, 'president': 484, 'school': 485, 'slaves': 486, 'vote': 487, 'ðŸ¤£': 488, '#': 489, 'Can': 490, 'UK': 491, 'created': 492, 'must': 493, 'BLACK': 494, 'Bible': 495, 'YOU': 496, 'agenda': 497, 'cop': 498, 'enough': 499, 'fight': 500, 'TO': 501, 'exist': 502, 'n': 503, 'remember': 504, 'treated': 505, 'AND': 506, 'Annie': 507, 'guess': 508, 'learn': 509, 'maybe': 510, 'times': 511, \"'d\": 512, 'Are': 513, 'instead': 514, 'under': 515, 'Now': 516, 'Wow': 517, 'lost': 518, 'might': 519, 'thinking': 520, 'words': 521, '3': 522, 'Good': 523, 'each': 524, 'jeans': 525, 'nice': 526, 'political': 527, 'choose': 528, 'racists': 529, 'become': 530, 'having': 531, 'happy': 532, 'shit': 533, 'yet': 534, 'completely': 535, 'die': 536, 'friend': 537, 'problems': 538, 'protesters': 539, 'wanted': 540, 'free': 541, 'gets': 542, 'joke': 543, 'least': 544, 'using': 545, 'LGBT': 546, 'Police': 547, 'US': 548, 'ask': 549, 'rights': 550, 'sin': 551, 'stand': 552, 'went': 553, ';': 554, 'African': 555, 'bi': 556, 'criminal': 557, 'either': 558, 'evil': 559, 'once': 560, '5': 561, 'Also': 562, 'Asian': 563, 'Lol': 564, '@Molly': 565, 'killing': 566, 'loves': 567, 'protesting': 568, 'wait': 569, 'â€™ve': 570, 'attention': 571, 'countries': 572, 'heart': 573, 'knows': 574, 'lmao': 575, 'sounds': 576, 'without': 577, 'Does': 578, 'For': 579, 'Maybe': 580, 'anti': 581, 'comes': 582, 'happen': 583, 'less': 584, 'looking': 585, 'okay': 586, 'controversial': 587, 'died': 588, 'dumb': 589, 'side': 590, 'society': 591, 'story': 592, 'Obama': 593, 'act': 594, 'democrats': 595, 'homophobic': 596, 'simply': 597, 'whatever': 598, 'Go': 599, 'IT': 600, 'mind': 601, 'poor': 602, 'pregnant': 603, 'seem': 604, 'votes': 605, 'working': 606, 'Bristol': 607, 'Did': 608, 'Please': 609, 'class': 610, 'government': 611, 'smart': 612, 'speak': 613, 'taking': 614, 'ðŸ¤¦': 615, 'ARE': 616, 'Let': 617, 'One': 618, 'changed': 619, 'during': 620, 'engineers': 621, 'forget': 622, 'full': 623, 'honestly': 624, 'racial': 625, 'OF': 626, 'Saying': 627, 'Some': 628, 'Walker': 629, 'between': 630, 'dude': 631, 'home': 632, 'ignorant': 633, 'law': 634, 'living': 635, 'Only': 636, 'Stop': 637, 'clearly': 638, 'fighting': 639, 'goes': 640, 'idiots': 641, 'nobody': 642, 'realize': 643, 'self': 644, 'totally': 645, 'watching': 646, '=': 647, 'Every': 648, 'Rebekah': 649, 'answer': 650, 'based': 651, 'bless': 652, 'cry': 653, 'listen': 654, 'speech': 655, 'videos': 656, 'violence': 657, '100': 658, 'Her': 659, 'LGBTQ': 660, 'beautiful': 661, 'born': 662, 'idea': 663, 'justice': 664, 'music': 665, 'system': 666, 'taken': 667, 'took': 668, '\\xa0 ': 669, '......': 670, 'Christians': 671, 'Fox': 672, 'Like': 673, 'THIS': 674, 'Then': 675, 'bit': 676, 'fine': 677, 'glad': 678, 'male': 679, 'meant': 680, 'mom': 681, 'myself': 682, 'power': 683, 'run': 684, 'slogan': 685, 'trade': 686, 'GOD': 687, 'bring': 688, 'happening': 689, 'high': 690, 'honest': 691, 'humans': 692, 'shut': 693, 'trader': 694, 'colour': 695, 'inspiring': 696, 'oppressed': 697, 'saw': 698, 'telling': 699, 'Of': 700, 'accept': 701, 'age': 702, 'boys': 703, 'crazy': 704, 'election': 705, 'example': 706, 'explain': 707, 'funny': 708, 'happens': 709, 'house': 710, 'majority': 711, 'party': 712, 'privilege': 713, 'together': 714, 'towards': 715, 'Or': 716, 'absolutely': 717, 'everybody': 718, 'eyes': 719, 'gone': 720, 'idiot': 721, 'seriously': 722, 'worse': 723, '   ': 724, 'beat': 725, 'field': 726, 'fucking': 727, 'knew': 728, 'lie': 729, 'rather': 730, 'shot': 731, 'simple': 732, 'Get': 733, 'almost': 734, 'asked': 735, 'asking': 736, 'bisexual': 737, 'death': 738, 'force': 739, 'hurt': 740, 'strong': 741, 'victim': 742, 'ðŸ¤”': 743, 'Great': 744, 'Those': 745, 'civil': 746, 'innocent': 747, 'later': 748, 'loved': 749, 'officers': 750, 'sick': 751, 'situation': 752, 'study': 753, 'voice': 754, 'worst': 755, 'Alive': 756, 'Most': 757, 'bunch': 758, 'fit': 759, 'horrible': 760, 'leave': 761, 'non': 762, 'pay': 763, 'peoples': 764, 'playing': 765, 'section': 766, 'stay': 767, 'wow': 768, 'Even': 769, 'IN': 770, 'WE': 771, 'blame': 772, 'entire': 773, 'head': 774, 'illegal': 775, 'r': 776, 'thinks': 777, 'wanna': 778, 'â€™ll': 779, 'Bernie': 780, 'closet': 781, 'crime': 782, 'found': 783, 'judge': 784, 'play': 785, 'politics': 786, 'prove': 787, 'research': 788, 'soon': 789, 'state': 790, 'treat': 791, 'Everyone': 792, 'Exactly': 793, 'baby': 794, 'issues': 795, 'mattered': 796, 'meet': 797, 'proud': 798, 'red': 799, 'rude': 800, 'shows': 801, 'British': 802, 'King': 803, 'Look': 804, 'Racism': 805, 'STEM': 806, 'South': 807, 'THAT': 808, 'able': 809, 'abuse': 810, 'disgusting': 811, 'facts': 812, 'move': 813, 'response': 814, 'scared': 815, 'truly': 816, 'turn': 817, 'wonder': 818, 'â€˜': 819, 'Marcus': 820, 'PEOPLE': 821, 'Sunshine': 822, 'USA': 823, 'beliefs': 824, 'calling': 825, 'crap': 826, 'cuz': 827, 'days': 828, 'divide': 829, 'earth': 830, 'except': 831, 'focus': 832, 'gays': 833, 'littlephilly': 834, 'middle': 835, 'murdered': 836, 'science': 837, 'social': 838, '@': 839, 'Christ': 840, 'Martin': 841, 'Sorry': 842, 'Thanks': 843, 'argument': 844, 'assume': 845, 'awesome': 846, 'beginning': 847, 'common': 848, 'correct': 849, 'emotional': 850, 'given': 851, 'groups': 852, 'second': 853, 'tho': 854, 'type': 855, 'Keep': 856, 'More': 857, 'ONLY': 858, 'Racist': 859, 'anybody': 860, 'bc': 861, 'bullshit': 862, 'church': 863, 'control': 864, 'create': 865, 'dead': 866, 'obviously': 867, 'omg': 868, 'supposed': 869, 'views': 870, 'virus': 871, 'NO': 872, 'SO': 873, 'Williams': 874, 'allowed': 875, 'along': 876, 'babies': 877, 'biggest': 878, 'certain': 879, 'cuffed': 880, 'culture': 881, 'evidence': 882, 'experience': 883, 'gun': 884, 'kinda': 885, 'liberal': 886, 'mad': 887, 'minority': 888, 'officer': 889, 'peace': 890, 're': 891, 'sexism': 892, 'Engineering': 893, 'President': 894, 'behind': 895, 'brought': 896, 'city': 897, 'covid': 898, 'hero': 899, 'laws': 900, 'save': 901, 'single': 902, 'trans': 903, 'Larry': 904, 'T': 905, 'actual': 906, 'books': 907, 'brother': 908, 'butt': 909, 'cares': 910, 'case': 911, 'check': 912, 'follow': 913, 'line': 914, 'looked': 915, 'moment': 916, 'perfect': 917, 'proof': 918, 'sound': 919, 'survivor': 920, 'topic': 921, 'â€™': 922, 'Jessica': 923, 'Luther': 924, 'Never': 925, 'america': 926, 'anymore': 927, 'channel': 928, 'definitely': 929, 'fake': 930, 'feminist': 931, 'freedom': 932, 'future': 933, 'logic': 934, 'reading': 935, 'rest': 936, 'seeing': 937, 'sexual': 938, 'shirt': 939, 'sweet': 940, 'term': 941, 'tired': 942, 'â€™d': 943, '8': 944, '>': 945, 'Ca': 946, 'Clinton': 947, 'alive': 948, 'brain': 949, 'built': 950, 'deserve': 951, 'difference': 952, 'exists': 953, 'false': 954, 'herself': 955, 'including': 956, 'itself': 957, 'kill': 958, 'lgbt': 959, 'met': 960, 'narrative': 961, 'nation': 962, 'obvious': 963, 'offended': 964, 'phrase': 965, 'removed': 966, 'toys': 967, 'watched': 968, 'ways': 969, '10': 970, 'At': 971, 'News': 972, 'Nobody': 973, 'Sanders': 974, 'TJ': 975, 'basically': 976, 'crying': 977, 'deal': 978, 'discrimination': 979, 'felt': 980, 'meaning': 981, 'message': 982, 'nI': 983, 'rid': 984, 'saved': 985, 'sold': 986, 'trump': 987, 'Brown': 988, 'Democratic': 989, 'LOVE': 990, 'YouTube': 991, 'conversation': 992, 'cute': 993, 'destroying': 994, 'due': 995, 'fault': 996, 'floyd': 997, 'half': 998, 'homosexual': 999, 'humanity': 1000, 'imagine': 1001, 'interested': 1002, 'lady': 1003, 'liberals': 1004, 'minorities': 1005, 'open': 1006, 'organization': 1007, 'speaking': 1008, 'till': 1009, 'tried': 1010, 'view': 1011, 'weird': 1012, '50': 1013, 'Asians': 1014, 'Crystal': 1015, 'Haskins': 1016, 'History': 1017, 'Michael': 1018, 'RACIST': 1019, 'Very': 1020, 'above': 1021, 'amount': 1022, 'brainwashed': 1023, 'confused': 1024, 'considered': 1025, 'destroy': 1026, 'giving': 1027, 'grow': 1028, 'homophobia': 1029, 'pandemic': 1030, 'ridiculous': 1031, 'serious': 1032, 'small': 1033, 'specific': 1034, 'star': 1035, 'students': 1036, 'wear': 1037, \"'S\": 1038, '@TheLegend27': 1039, 'Africans': 1040, 'Anyone': 1041, 'BS': 1042, 'DO': 1043, 'Have': 1044, 'Kids': 1045, 'LOL': 1046, 'S': 1047, 'bet': 1048, 'body': 1049, 'break': 1050, 'bro': 1051, 'burning': 1052, 'business': 1053, 'communities': 1054, 'complaining': 1055, 'currently': 1056, 'feminism': 1057, 'folks': 1058, 'likely': 1059, 'mouth': 1060, 'needed': 1061, 'often': 1062, 'politicians': 1063, 'possible': 1064, 'thanks': 1065, 'vs': 1066, 'wearing': 1067, 'wrote': 1068, '@Michael': 1069, '@The': 1070, 'B': 1071, 'G': 1072, 'Here': 1073, 'LGBTQ+': 1074, 'Parsons': 1075, 'Right': 1076, 'With': 1077, '_': 1078, 'creating': 1079, 'degree': 1080, 'feelings': 1081, 'forced': 1082, 'game': 1083, 'gives': 1084, 'hating': 1085, 'hatred': 1086, 'luck': 1087, 'main': 1088, 'picture': 1089, 'supporting': 1090, 'title': 1091, '60': 1092, 'New': 1093, 'Really': 1094, 'THEY': 1095, 'U': 1096, 'WHITE': 1097, 'Which': 1098, 'Women': 1099, 'World': 1100, 'alm': 1101, 'blood': 1102, 'blue': 1103, 'cool': 1104, 'debate': 1105, 'definition': 1106, 'doubt': 1107, 'fall': 1108, 'feeling': 1109, 'fields': 1110, 'hated': 1111, 'ignore': 1112, 'inspired': 1113, 'interesting': 1114, 'longer': 1115, 'lying': 1116, 'mother': 1117, 'order': 1118, 'personally': 1119, 'played': 1120, 'public': 1121, 'putting': 1122, 'questions': 1123, 'reality': 1124, 'riots': 1125, 'sir': 1126, 'states': 1127, 'studying': 1128, 'takes': 1129, 'thousands': 1130, 'understanding': 1131, '20': 1132, '@Jack': 1133, 'By': 1134, 'China': 1135, 'FOR': 1136, 'J': 1137, 'LIFE': 1138, 'M': 1139, 'ONE': 1140, 'Paul': 1141, 'WAS': 1142, 'action': 1143, 'alone': 1144, 'ancestors': 1145, 'arrest': 1146, 'attack': 1147, 'brown': 1148, 'citizens': 1149, 'clear': 1150, 'college': 1151, 'cried': 1152, 'doctor': 1153, 'dream': 1154, 'easy': 1155, 'equally': 1156, 'everyday': 1157, 'forgot': 1158, 'generation': 1159, 'hand': 1160, 'involved': 1161, 'jobs': 1162, 'light': 1163, 'loving': 1164, 'mature': 1165, 'oppression': 1166, 'otherwise': 1167, 'outside': 1168, 'peaceful': 1169, 'planet': 1170, 'points': 1171, 'queen': 1172, 'set': 1173, 'soul': 1174, 'special': 1175, 'taught': 1176, 'top': 1177, 'uh': 1178, '12': 1179, '6': 1180, 'C': 1181, 'Conversion': 1182, 'Funny': 1183, 'Hillary': 1184, 'Jimmy': 1185, 'ME': 1186, 'MY': 1187, 'Man': 1188, 'Me': 1189, 'Remember': 1190, 'Too': 1191, 'WHAT': 1192, 'YOUR': 1193, 'afraid': 1194, 'apart': 1195, 'bringing': 1196, 'claim': 1197, 'current': 1198, 'cut': 1199, 'finally': 1200, 'hold': 1201, 'jail': 1202, 'lack': 1203, 'mental': 1204, 'million': 1205, 'millions': 1206, 'pathetic': 1207, 'sometimes': 1208, 'starting': 1209, 'stereotype': 1210, 'street': 1211, 'ta': 1212, 'tells': 1213, 'turned': 1214, 'violent': 1215, 'wing': 1216, 'wonderful': 1217, 'y': 1218, 'yea': 1219, '@Jessica': 1220, 'ALM': 1221, 'Being': 1222, 'Democrat': 1223, 'His': 1224, 'Imagine': 1225, 'Jewish': 1226, 'Nothing': 1227, 'Ok': 1228, 'assuming': 1229, 'believes': 1230, 'career': 1231, 'christian': 1232, 'continue': 1233, 'crimes': 1234, 'etc': 1235, 'expect': 1236, 'fear': 1237, 'figure': 1238, 'fire': 1239, 'form': 1240, 'fun': 1241, 'held': 1242, 'historical': 1243, 'ideology': 1244, 'industry': 1245, 'math': 1246, 'mentality': 1247, 'mine': 1248, 'missed': 1249, 'modern': 1250, 'office': 1251, 'older': 1252, 'opinions': 1253, 'respectful': 1254, 'rich': 1255, 'sexist': 1256, 'shame': 1257, 'speaks': 1258, 'surprised': 1259, 'thoughts': 1260, 'unless': 1261, 'value': 1262, 'victims': 1263, 'wanting': 1264, 'week': 1265, 'Birt': 1266, 'Britain': 1267, 'Bus': 1268, 'Come': 1269, 'Europe': 1270, 'Lord': 1271, 'Party': 1272, 'Queen': 1273, 'Take': 1274, 'United': 1275, 'across': 1276, 'actions': 1277, 'angry': 1278, 'annie': 1279, 'bigger': 1280, 'boo': 1281, 'booing': 1282, 'chance': 1283, 'communist': 1284, 'decades': 1285, 'decide': 1286, 'destroyed': 1287, 'dying': 1288, 'eye': 1289, 'fan': 1290, 'feels': 1291, 'hateful': 1292, 'movie': 1293, 'names': 1294, 'normal': 1295, 'number': 1296, 'paid': 1297, 'period': 1298, 'protestors': 1299, 'purpose': 1300, 'pushing': 1301, 'raised': 1302, 'showing': 1303, 'stopped': 1304, 'talks': 1305, 'transgender': 1306, 'waiting': 1307, 'water': 1308, 'win': 1309, '19': 1310, 'After': 1311, 'Blacks': 1312, 'Bless': 1313, 'Churchill': 1314, 'English': 1315, 'HE': 1316, 'Hey': 1317, 'Jones': 1318, 'Life': 1319, 'Pop': 1320, 'Republicans': 1321, 'SHE': 1322, 'advocate': 1323, 'beating': 1324, 'close': 1325, 'closeted': 1326, 'colors': 1327, 'discussion': 1328, 'dislike': 1329, 'division': 1330, 'economy': 1331, 'especially': 1332, 'existence': 1333, 'extremely': 1334, 'food': 1335, 'fuck': 1336, 'gay': 1337, 'grew': 1338, 'haha': 1339, 'hands': 1340, 'hit': 1341, 'include': 1342, 'includes': 1343, 'inspirational': 1344, 'interviewer': 1345, 'land': 1346, 'late': 1347, 'lies': 1348, 'listening': 1349, 'major': 1350, 'mention': 1351, 'miss': 1352, 'offensive': 1353, 'protect': 1354, 'responsible': 1355, 'safe': 1356, 'somebody': 1357, 'statistics': 1358, 't': 1359, 'teach': 1360, 'tech': 1361, 'usually': 1362, 'western': 1363, 'whether': 1364, 'worked': 1365, 'works': 1366, 'worry': 1367, '.......': 1368, '@Alex': 1369, 'Actually': 1370, 'Bill': 1371, 'Chinese': 1372, 'L': 1373, 'Marxist': 1374, 'N': 1375, 'OMG': 1376, 'Our': 1377, 'STOP': 1378, 'Smith': 1379, 'Soros': 1380, 'TOO': 1381, 'Time': 1382, 'Wait': 1383, 'abortion': 1384, 'according': 1385, 'agreeing': 1386, 'anywhere': 1387, 'ass': 1388, 'award': 1389, 'becoming': 1390, 'buy': 1391, 'changing': 1392, 'chose': 1393, 'complain': 1394, 'couple': 1395, 'criminals': 1396, 'dad': 1397, 'fools': 1398, 'helped': 1399, 'himself': 1400, 'idk': 1401, 'internet': 1402, 'legal': 1403, 'liked': 1404, 'likes': 1405, 'lose': 1406, 'madonna': 1407, 'mate': 1408, 'months': 1409, 'none': 1410, 'pandering': 1411, 'personal': 1412, 'places': 1413, 'post': 1414, 'rate': 1415, 'realized': 1416, 'regardless': 1417, 'repeat': 1418, 'river': 1419, 'schools': 1420, 'shall': 1421, 'spreading': 1422, 'stereotypes': 1423, 'super': 1424, 'terrorist': 1425, 'within': 1426, 'worth': 1427, 'written': 1428, '$': 1429, '@Theodore': 1430, 'BE': 1431, 'Both': 1432, 'Catholic': 1433, 'Debbie': 1434, 'Elder': 1435, 'Hope': 1436, 'However': 1437, 'India': 1438, 'Slavery': 1439, 'WHY': 1440, 'WILL': 1441, 'Was': 1442, 'add': 1443, 'alot': 1444, 'american': 1445, 'anyway': 1446, 'arrested': 1447, 'asian': 1448, 'b': 1449, 'beaten': 1450, 'card': 1451, 'century': 1452, 'company': 1453, 'destruction': 1454, 'everywhere': 1455, 'forever': 1456, 'forgotten': 1457, 'four': 1458, 'goal': 1459, 'information': 1460, 'interest': 1461, 'known': 1462, 'leftist': 1463, 'list': 1464, 'looting': 1465, 'low': 1466, 'mentioned': 1467, 'native': 1468, 'neck': 1469, 'nonsense': 1470, 'pansexual': 1471, 'pick': 1472, 'queer': 1473, 'reply': 1474, 'running': 1475, 'smh': 1476, 'song': 1477, 'standing': 1478, 'student': 1479, 'targeted': 1480, 'toy': 1481, 'traders': 1482, 'unarmed': 1483, 'wake': 1484, 'weak': 1485, 'ya': 1486, 'yours': 1487, '--': 1488, '@Dus': 1489, 'Blm': 1490, 'Donald': 1491, 'Hitler': 1492, 'Jackson': 1493, 'Johnson': 1494, 'Paysour': 1495, 'S.': 1496, 'THERE': 1497, 'Tell': 1498, 'UP': 1499, 'abused': 1500, 'ahead': 1501, 'ai': 1502, 'apparently': 1503, 'argue': 1504, 'ashamed': 1505, 'attacked': 1506, 'car': 1507, 'causes': 1508, 'cities': 1509, 'dark': 1510, 'deserves': 1511, 'devil': 1512, 'eat': 1513, 'fair': 1514, 'fired': 1515, 'fix': 1516, 'genuine': 1517, 'ha': 1518, 'hide': 1519, 'huge': 1520, 'hundreds': 1521, 'ideas': 1522, 'ignorance': 1523, 'kept': 1524, 'kills': 1525, 'legend': 1526, 'level': 1527, 'link': 1528, 'lots': 1529, 'missing': 1530, 'morons': 1531, 'mostly': 1532, 'murder': 1533, 'natural': 1534, 'owners': 1535, 'perspective': 1536, 'population': 1537, 'poverty': 1538, 'precious': 1539, 'privileged': 1540, 'propaganda': 1541, 'quote': 1542, 'ready': 1543, 'recently': 1544, 'relevant': 1545, 'send': 1546, 'sins': 1547, 'son': 1548, 'sort': 1549, 'spread': 1550, 'stands': 1551, 'step': 1552, 'stomach': 1553, 'systemic': 1554, 'welfare': 1555, 'wtf': 1556, \"y'\": 1557, '2015': 1558, '25': 1559, '@Anna': 1560, 'ANY': 1561, 'Amen': 1562, 'Canada': 1563, 'Dumse': 1564, 'First': 1565, 'From': 1566, 'HAVE': 1567, 'Hannity': 1568, 'LIKE': 1569, 'MATTERS': 1570, 'MLK': 1571, 'Matters': 1572, 'Men': 1573, 'Rose': 1574, 'Same': 1575, 'Should': 1576, 'Someone': 1577, 'Tagerius': 1578, 'WITH': 1579, 'acting': 1580, 'animals': 1581, 'appreciate': 1582, 'blaming': 1583, 'btw': 1584, 'building': 1585, 'certainly': 1586, 'consider': 1587, 'context': 1588, 'corona': 1589, 'd': 1590, 'disagreeing': 1591, 'disgraceful': 1592, 'dislikes': 1593, 'double': 1594, 'dumbass': 1595, 'education': 1596, 'exact': 1597, 'excuse': 1598, 'father': 1599, 'feminists': 1600, 'gaydar': 1601, 'general': 1602, 'huh': 1603, 'hurting': 1604, 'hypocrisy': 1605, 'inside': 1606, 'jump': 1607, 'keeping': 1608, 'knee': 1609, 'knowing': 1610, 'learning': 1611, 'males': 1612, 'minded': 1613, 'monument': 1614, 'moron': 1615, 'negative': 1616, 'piece': 1617, 'pride': 1618, 'pull': 1619, 'quite': 1620, 'sell': 1621, 'species': 1622, 'streets': 1623, 'tear': 1624, 'terrible': 1625, 'turns': 1626, 'woke': 1627, 'youtube': 1628, '........': 1629, '14': 1630, '@Maggie': 1631, '@Tyrone': 1632, 'Chicago': 1633, 'D': 1634, 'England': 1635, 'Give': 1636, 'John': 1637, 'Mexican': 1638, 'Much': 1639, 'NOW': 1640, 'Next': 1641, 'ON': 1642, 'Okay': 1643, 'Priti': 1644, 'States': 1645, 'Taylor': 1646, 'Unless': 1647, 'WHO': 1648, 'Whites': 1649, 'XD': 1650, 'absolute': 1651, 'accepting': 1652, 'arguing': 1653, 'aware': 1654, 'battle': 1655, 'caused': 1656, 'classes': 1657, 'complete': 1658, 'council': 1659, 'crystal': 1660, 'cuff': 1661, 'damn': 1662, 'dangerous': 1663, 'deaths': 1664, 'democratic': 1665, 'deny': 1666, 'difficult': 1667, 'drug': 1668, 'e': 1669, 'early': 1670, 'ended': 1671, 'george': 1672, 'helping': 1673, 'helps': 1674, 'individual': 1675, 'inspiration': 1676, 'join': 1677, 'language': 1678, 'learned': 1679, 'lived': 1680, 'mixed': 1681, 'mob': 1682, 'near': 1683, 'pain': 1684, 'pointed': 1685, 'pointing': 1686, 'posted': 1687, 'powerful': 1688, 'present': 1689, 'property': 1690, 'realise': 1691, 'reasons': 1692, 'related': 1693, 'sentence': 1694, 'shoot': 1695, 'sign': 1696, 'singer': 1697, 'subject': 1698, 'suffering': 1699, 'supremacy': 1700, 'swear': 1701, 'teacher': 1702, 'tearing': 1703, 'tears': 1704, 'terrorists': 1705, 'thread': 1706, 'three': 1707, 'torture': 1708, 'upon': 1709, 'wise': 1710, '<3': 1711, '@Jimmy': 1712, 'An': 1713, 'Big': 1714, 'CNN': 1715, 'Censored': 1716, 'Colston': 1717, 'Cone': 1718, 'Edward': 1719, 'Hispanic': 1720, 'LMAO': 1721, 'Many': 1722, 'Patel': 1723, 'Race': 1724, 'Satan': 1725, 'Since': 1726, 'TheLegend27': 1727, 'Truth': 1728, 'adults': 1729, 'armed': 1730, 'atheist': 1731, 'attacking': 1732, 'belongs': 1733, 'brave': 1734, 'bruh': 1735, 'cases': 1736, 'causing': 1737, 'deep': 1738, 'democrat': 1739, 'differently': 1740, 'discriminated': 1741, 'easily': 1742, 'educated': 1743, 'energy': 1744, 'english': 1745, 'environment': 1746, 'f': 1747, 'front': 1748, 'garbage': 1749, 'generations': 1750, 'gods': 1751, 'hates': 1752, 'hearing': 1753, 'higher': 1754, 'influence': 1755, 'intelligent': 1756, 'large': 1757, 'leaders': 1758, 'lifes': 1759, 'multiple': 1760, 'nations': 1761, 'nearly': 1762, 'original': 1763, 'plenty': 1764, 'quit': 1765, 'recent': 1766, 'referring': 1767, 'reminds': 1768, 'somehow': 1769, 'suffer': 1770, 'testament': 1771, 'third': 1772, 'throw': 1773, 'thugs': 1774, 'troll': 1775, 'version': 1776, 'walk': 1777, 'west': 1778, 'whoring': 1779, 'younger': 1780, 'ðŸ¤·': 1781, '    ': 1782, '9': 1783, '@Heather': 1784, '@John': 1785, 'AS': 1786, 'Antifa': 1787, 'Clearly': 1788, \"DON'T\": 1789, 'EVER': 1790, 'Engineer': 1791, 'Especially': 1792, 'GET': 1793, 'Human': 1794, 'Islam': 1795, 'JUST': 1796, 'Justice': 1797, 'OR': 1798, 'Omg': 1799, 'Still': 1800, 'Such': 1801, 'True': 1802, 'U.S.': 1803, 'Will': 1804, 'agreed': 1805, 'attitude': 1806, 'beyond': 1807, 'blind': 1808, 'booed': 1809, 'bottom': 1810, 'brothers': 1811, 'calm': 1812, 'commit': 1813, 'constantly': 1814, 'cultural': 1815, 'denial': 1816, 'differences': 1817, 'dog': 1818, 'effect': 1819, 'fail': 1820, 'families': 1821, 'famous': 1822, 'females': 1823, 'forward': 1824, 'global': 1825, 'gotten': 1826, 'harm': 1827, 'houses': 1828, 'insane': 1829, 'interviews': 1830, 'justify': 1831, 'leaving': 1832, 'lgbtq': 1833, 'lgbtq+': 1834, 'mistakes': 1835, 'nYou': 1836, 'night': 1837, 'opposite': 1838, 'owner': 1839, 'parade': 1840, 'physical': 1841, 'plan': 1842, 'prejudice': 1843, 'proven': 1844, 'rare': 1845, 'remove': 1846, 'risk': 1847, 'sadly': 1848, 'scary': 1849, 'selling': 1850, 'separate': 1851, 'sisters': 1852, 'sitting': 1853, 'solve': 1854, 'superior': 1855, 'superiority': 1856, 'supported': 1857, 'teachers': 1858, 'trust': 1859, 'unborn': 1860, 'uneducated': 1861, 'upset': 1862, 'vandalism': 1863, 'waste': 1864, 'weeks': 1865, 'womb': 1866, 'x': 1867, 'â€¦': 1868, 'ðŸ¥º': 1869, '11': 1870, '13': 1871, 'Any': 1872, 'Ask': 1873, 'BUT': 1874, 'Be': 1875, 'Change': 1876, 'Christianity': 1877, 'Cyndi': 1878, 'Davis': 1879, 'Earth': 1880, 'East': 1881, 'Europeans': 1882, 'Evil': 1883, 'Hate': 1884, 'Interesting': 1885, 'Irish': 1886, 'JESUS': 1887, 'Listen': 1888, 'NEVER': 1889, 'On': 1890, 'Russia': 1891, 'Sometimes': 1892, 'Sure': 1893, 'Their': 1894, 'Think': 1895, 'Toronto': 1896, 'Would': 1897, 'admit': 1898, 'adult': 1899, 'americans': 1900, 'annoying': 1901, 'apply': 1902, 'belief': 1903, 'build': 1904, 'buildings': 1905, 'bullied': 1906, 'burn': 1907, 'changes': 1908, 'china': 1909, 'claims': 1910, 'computer': 1911, 'concerned': 1912, 'decided': 1913, 'deleted': 1914, 'despite': 1915, 'drugs': 1916, 'educate': 1917, 'enjoy': 1918, 'five': 1919, 'fool': 1920, 'former': 1921, 'gayest': 1922, 'grievances': 1923, 'ground': 1924, 'guns': 1925, 'heaven': 1926, 'hey': 1927, 'hug': 1928, 'hypocritical': 1929, 'identify': 1930, 'irony': 1931, 'kicking': 1932, 'knowledge': 1933, 'laugh': 1934, 'laughing': 1935, 'leader': 1936, 'legos': 1937, 'massive': 1938, 'minute': 1939, 'mistreated': 1940, 'month': 1941, 'museum': 1942, 'neither': 1943, 'noticed': 1944, 'personality': 1945, 'positive': 1946, 'pray': 1947, 'pretend': 1948, 'profile': 1949, 'relate': 1950, 'result': 1951, 'riot': 1952, 'robbed': 1953, 'role': 1954, 'room': 1955, 'rule': 1956, 'sheep': 1957, 'sides': 1958, 'similar': 1959, 'sis': 1960, 'standards': 1961, 'stuck': 1962, 'suicide': 1963, 'supporter': 1964, 'supporters': 1965, 'supports': 1966, 'throughout': 1967, 'throwing': 1968, 'total': 1969, 'train': 1970, 'trouble': 1971, 'types': 1972, 'wave': 1973, 'witch': 1974, 'yep': 1975, 'yâ€™': 1976, 'ðŸ¤®': 1977, '15': 1978, '7': 1979, 'Again': 1980, 'Civil': 1981, 'Clown': 1982, 'DONT': 1983, 'Dude': 1984, 'End': 1985, 'Germany': 1986, 'Girl': 1987, 'Haha': 1988, 'Hudson': 1989, 'Jules': 1990, 'K': 1991, 'Nice': 1992, 'OK': 1993, 'OUR': 1994, 'Plantation': 1995, 'RACE': 1996, 'Sad': 1997, 'See': 1998, 'Survivor': 1999, 'THEM': 2000, 'Wake': 2001, 'accepted': 2002, 'african': 2003, 'analogy': 2004, 'apologize': 2005, 'behaviour': 2006, 'brainwashing': 2007, 'calls': 2008, 'campaign': 2009, 'capable': 2010, 'cars': 2011, 'catholic': 2012, 'claiming': 2013, 'clue': 2014, 'colours': 2015, 'construction': 2016, 'content': 2017, 'coronavirus': 2018, 'daily': 2019, 'defend': 2020, 'disagrees': 2021, 'distancing': 2022, 'dolls': 2023, 'donate': 2024, 'doomed': 2025, 'encouraged': 2026, 'entitled': 2027, 'experiences': 2028, 'fat': 2029, 'fathers': 2030, 'fought': 2031, 'haircut': 2032, 'haters': 2033, 'however': 2034, 'ignored': 2035, 'immediately': 2036, 'incredible': 2037, 'individuals': 2038, 'injustice': 2039, 'inspire': 2040, 'insult': 2041, 'intelligence': 2042, 'kinds': 2043, 'lay': 2044, 'lead': 2045, 'lets': 2046, 'lockdown': 2047, 'lucky': 2048, 'mass': 2049, 'members': 2050, 'military': 2051, 'movements': 2052, 'nor': 2053, 'owned': 2054, 'paint': 2055, 'peacefully': 2056, 'persons': 2057, 'position': 2058, 'pulled': 2059, 'push': 2060, 'religions': 2061, 'repent': 2062, 'represent': 2063, 'revolution': 2064, 'share': 2065, 'shown': 2066, 'sinner': 2067, 'starts': 2068, 'stated': 2069, 'statements': 2070, 'stick': 2071, 'strange': 2072, 'successful': 2073, 'suck': 2074, 'survived': 2075, 'tbh': 2076, 'therapist': 2077, 'therefore': 2078, 'translated': 2079, 'trash': 2080, 'tribes': 2081, 'understood': 2082, 'whose': 2083, 'workers': 2084, '18': 2085, '1st': 2086, '2016': 2087, '@A': 2088, '@Brutal': 2089, '@J': 2090, 'BIBLE': 2091, 'Blue': 2092, 'Covid': 2093, 'Day': 2094, 'Dems': 2095, 'Doctor': 2096, 'E': 2097, 'European': 2098, 'F': 2099, 'Holy': 2100, 'House': 2101, 'Huynh': 2102, 'ITS': 2103, 'Indian': 2104, 'LaBrae': 2105, 'MORE': 2106, 'Middle': 2107, 'Mr': 2108, 'NEED': 2109, 'Notice': 2110, 'Once': 2111, 'Pride': 2112, 'R': 2113, 'Ryan': 2114, 'Sadly': 2115, 'Seriously': 2116, 'Shut': 2117, 'Slave': 2118, 'TRUTH': 2119, 'Unfortunately': 2120, 'X': 2121, 'Yâ€™all': 2122, 'acts': 2123, 'africa': 2124, 'ages': 2125, 'allow': 2126, 'among': 2127, 'artist': 2128, 'asians': 2129, 'audience': 2130, 'basis': 2131, 'bigotry': 2132, 'bill': 2133, 'botox': 2134, 'bs': 2135, 'butch': 2136, 'c': 2137, 'camera': 2138, 'camp': 2139, 'camps': 2140, 'chaos': 2141, 'character': 2142, 'charge': 2143, 'chemical': 2144, 'clowns': 2145, 'concept': 2146, 'conservatives': 2147, 'considering': 2148, 'corrupt': 2149, 'damage': 2150, 'date': 2151, 'defending': 2152, 'dies': 2153, 'disgrace': 2154, 'disrespectful': 2155, 'dollars': 2156, 'drawing': 2157, 'elected': 2158, 'elections': 2159, 'elite': 2160, 'enemy': 2161, 'enslaved': 2162, 'episode': 2163, 'express': 2164, 'extreme': 2165, 'failed': 2166, 'fashion': 2167, 'fell': 2168, 'fellow': 2169, 'fully': 2170, 'funded': 2171, 'greatest': 2172, 'grown': 2173, 'guilty': 2174, 'harder': 2175, 'highly': 2176, 'idiotic': 2177, 'implies': 2178, 'internalized': 2179, 'judged': 2180, 'leftists': 2181, 'legit': 2182, 'lesbians': 2183, 'letting': 2184, 'mask': 2185, 'mistake': 2186, 'nThe': 2187, 'nature': 2188, 'nnI': 2189, 'notice': 2190, 'o': 2191, 'ourselves': 2192, 'paying': 2193, 'plain': 2194, 'prefer': 2195, 'pretending': 2196, 'program': 2197, 'publicity': 2198, 'raimey': 2199, 'republicans': 2200, 'resisting': 2201, 'rioters': 2202, 'saint': 2203, 'screaming': 2204, 'sees': 2205, 'segregation': 2206, 'selfish': 2207, 'showed': 2208, 'somewhere': 2209, 'spend': 2210, 'spoken': 2211, 'spot': 2212, 'stupidity': 2213, 'suppose': 2214, 'systematic': 2215, 'talked': 2216, 'threat': 2217, 'tough': 2218, 'town': 2219, 'trained': 2220, 'uk': 2221, 'uses': 2222, 've': 2223, 'visit': 2224, 'website': 2225, 'worship': 2226, 'yellow': 2227, '30': 2228, '80': 2229, '@Hai': 2230, '@I': 2231, '@Mark': 2232, 'AIDS': 2233, 'Adam': 2234, 'Always': 2235, 'Another': 2236, 'B.': 2237, 'BBC': 2238, 'BY': 2239, 'Beautiful': 2240, 'Before': 2241, 'Bottom': 2242, 'Bunch': 2243, 'CAN': 2244, 'Candace': 2245, 'EVERYTHING': 2246, 'Everything': 2247, 'Finally': 2248, 'France': 2249, 'GOOD': 2250, 'Got': 2251, 'HIM': 2252, 'Indians': 2253, 'Jonathan': 2254, 'Leave': 2255, 'Lee': 2256, 'Literally': 2257, 'Lmao': 2258, 'MADONNA': 2259, 'Marxists': 2260, 'May': 2261, 'None': 2262, 'Obviously': 2263, 'Probably': 2264, 'RIGHT': 2265, 'Sherriff': 2266, 'Stay': 2267, 'Tea': 2268, 'Theodore': 2269, 'Washington': 2270, 'Way': 2271, 'Whatever': 2272, 'Wired': 2273, 'Xx': 2274, 'account': 2275, 'add#11': 2276, 'added': 2277, 'addict': 2278, 'andrea': 2279, 'article': 2280, 'average': 2281, 'awful': 2282, 'basement': 2283, 'becomes': 2284, 'birth': 2285, 'birthday': 2286, 'bleed': 2287, 'bother': 2288, 'breath': 2289, 'brings': 2290, 'broken': 2291, 'committed': 2292, 'condemned': 2293, 'constitution': 2294, 'controlled': 2295, 'describe': 2296, 'design': 2297, 'destructive': 2298, 'disliked': 2299, 'dogs': 2300, 'dress': 2301, 'elites': 2302, 'ethnic': 2303, 'faced': 2304, 'focusing': 2305, 'gaming': 2306, 'girlfriend': 2307, 'growing': 2308, 'haired': 2309, 'heterosexual': 2310, 'homophobe': 2311, 'homosexuals': 2312, 'hot': 2313, 'identity': 2314, 'ignoring': 2315, 'image': 2316, 'importance': 2317, 'included': 2318, 'judging': 2319, 'keeps': 2320, 'kick': 2321, 'kidding': 2322, 'king': 2323, 'lines': 2324, 'load': 2325, 'loser': 2326, 'masks': 2327, 'messed': 2328, 'minds': 2329, 'moved': 2330, 'moving': 2331, 'nowhere': 2332, 'nuclear': 2333, 'odd': 2334, 'offense': 2335, 'opportunity': 2336, 'organisation': 2337, 'orientation': 2338, 'parts': 2339, 'passed': 2340, 'platform': 2341, 'prison': 2342, 'pushed': 2343, 'raise': 2344, 'reaction': 2345, 'represented': 2346, 'rn': 2347, 'schuiling': 2348, 'seemed': 2349, 'sent': 2350, 'served': 2351, 'several': 2352, 'shape': 2353, 'sharing': 2354, 'shoes': 2355, 'shootings': 2356, 'sinners': 2357, 'sister': 2358, 'site': 2359, 'sky': 2360, 'soft': 2361, 'software': 2362, 'sooo': 2363, 'source': 2364, 'spirit': 2365, 'standard': 2366, 'stats': 2367, 'status': 2368, 'stfu': 2369, 'stood': 2370, 'struggle': 2371, 'subjects': 2372, 'sucks': 2373, 'suddenly': 2374, 'survive': 2375, 'sweater': 2376, 'teaching': 2377, 'terms': 2378, 'triggered': 2379, 'valid': 2380, 'vid': 2381, 'voting': 2382, 'wat': 2383, 'wealth': 2384, 'willing': 2385, 'won': 2386, 'wondering': 2387, '2012': 2388, '2019': 2389, '3rd': 2390, '90': 2391, '@CÃ¡ca': 2392, '@Eric': 2393, '@Hudson': 2394, '@Marco': 2395, '@Mr': 2396, '@Zackary': 2397, '@kennedy': 2398, '@wow': 2399, 'AMERICA': 2400, 'AN': 2401, 'AT': 2402, 'Agreed': 2403, 'Boo': 2404, 'Cause': 2405, 'Could': 2406, 'DOES': 2407, 'EVERY': 2408, 'Everybody': 2409, 'Except': 2410, 'GIRL': 2411, 'HOW': 2412, 'Ha': 2413, 'Homosexuality': 2414, 'Honesty': 2415, 'Iraq': 2416, 'Israel': 2417, 'James': 2418, 'Jane': 2419, 'Jeans': 2420, 'LGBT+': 2421, 'Milis': 2422, 'Name': 2423, 'Nation': 2424, 'Native': 2425, 'Owens': 2426, 'Patriot': 2427, 'Plus': 2428, 'Political': 2429, 'REAL': 2430, 'Respect': 2431, 'Richard': 2432, 'Rivas': 2433, 'SAY': 2434, 'Sasha': 2435, 'Schmidt': 2436, 'Scott': 2437, 'Seomra': 2438, 'Shepard': 2439, 'Spraoi': 2440, 'Therapy': 2441, 'Tyrone': 2442, 'VERY': 2443, 'WOW': 2444, 'West': 2445, 'Whoever': 2446, 'Whoring': 2447, 'Wtf': 2448, 'YES': 2449, 'Yep': 2450, 'Yup': 2451, 'adorable': 2452, 'agendas': 2453, 'album': 2454, 'arguments': 2455, 'assholes': 2456, 'attracted': 2457, 'badass': 2458, 'balance': 2459, 'bank': 2460, 'behavior': 2461, 'believing': 2462, 'below': 2463, 'boomer': 2464, 'bored': 2465, 'bought': 2466, 'bout': 2467, 'breathe': 2468, 'businesses': 2469, 'cat': 2470, 'caught': 2471, 'centuries': 2472, 'clever': 2473, 'compared': 2474, 'comprehend': 2475, 'conquer': 2476, 'conservative': 2477, 'countless': 2478, 'court': 2479, 'cover': 2480, 'credit': 2481, 'daughter': 2482, 'decent': 2483, 'diversity': 2484, 'divided': 2485, 'east': 2486, 'eating': 2487, 'erase': 2488, 'explaining': 2489, 'explanation': 2490, 'faith': 2491, 'filled': 2492, 'fish': 2493, 'further': 2494, 'gain': 2495, 'glorifying': 2496, 'grave': 2497, 'gross': 2498, 'happiness': 2499, 'historic': 2500, 'holy': 2501, 'hostile': 2502, 'hours': 2503, 'idol': 2504, 'inclusive': 2505, 'joking': 2506, 'ladies': 2507, 'literal': 2508, 'local': 2509, 'lock': 2510, 'mechanical': 2511, 'mensah': 2512, 'mentally': 2513, 'mindset': 2514, 'monuments': 2515, 'nAnd': 2516, 'nWe': 2517, 'necessary': 2518, 'neighborhood': 2519, 'offend': 2520, 'official': 2521, 'opportunities': 2522, 'pan': 2523, 'path': 2524, 'perfectly': 2525, 'picked': 2526, 'pro': 2527, 'process': 2528, 'provide': 2529, 'pulling': 2530, 'reasonable': 2531, 'record': 2532, 'representing': 2533, 'republican': 2534, 'ruined': 2535, 'sa': 2536, 'sake': 2537, 'secret': 2538, 'sensitive': 2539, 'service': 2540, 'sherriff': 2541, 'shout': 2542, 'shouting': 2543, 'specifically': 2544, 'spoke': 2545, 'stopping': 2546, 'stories': 2547, 'strength': 2548, 'studies': 2549, 'succeed': 2550, 'supremacists': 2551, 'taxes': 2552, 'teenage': 2553, 'tf': 2554, 'theory': 2555, 'touch': 2556, 'treating': 2557, 'turning': 2558, 'unfortunately': 2559, 'victimhood': 2560, 'vulnerable': 2561, 'w': 2562, 'welcome': 2563, 'wife': 2564, 'worldwide': 2565, 'yo': 2566, '2021': 2567, '21': 2568, '24': 2569, '400': 2570, '@American': 2571, '@BBC': 2572, '@Baden': 2573, '@Gameplay': 2574, '@James': 2575, '@Johnathan': 2576, '@Jonathan': 2577, '@Po': 2578, '@connie': 2579, 'ABOUT': 2580, 'Absolutely': 2581, 'Ah': 2582, 'Alex': 2583, 'Amazing': 2584, 'Anna': 2585, 'Anything': 2586, 'Apparently': 2587, 'Arreola': 2588, 'Asia': 2589, 'BECAUSE': 2590, 'Bro': 2591, 'Cops': 2592, 'Covid-19': 2593, 'EVEN': 2594, 'Equality': 2595, 'FROM': 2596, 'Fear': 2597, 'GO': 2598, 'Gays': 2599, 'Gods': 2600, 'Google': 2601, 'Grant': 2602, 'HAS': 2603, 'HATE': 2604, 'Henderson': 2605, 'Hispanics': 2606, 'Honestly': 2607, 'Hopefully': 2608, 'ISIS': 2609, 'Jack': 2610, 'Laurencya': 2611, 'Left': 2612, 'Lets': 2613, 'Liberal': 2614, 'Liberals': 2615, 'Long': 2616, 'MADE': 2617, 'MEN': 2618, 'MSM': 2619, 'Maas': 2620, 'Mike': 2621, 'Mine': 2622, 'Movement': 2623, 'Muslim': 2624, 'Nelson': 2625, 'O': 2626, 'Po': 2627, 'Pretty': 2628, 'Protest': 2629, 'Put': 2630, 'Read': 2631, 'Red': 2632, 'Republican': 2633, 'Russian': 2634, 'SHERIFF': 2635, 'Saddam': 2636, 'Says': 2637, 'School': 2638, 'Show': 2639, 'Sky': 2640, 'Society': 2641, 'Star': 2642, 'Statue': 2643, 'Steven': 2644, 'Stone': 2645, 'TED': 2646, 'THANK': 2647, 'THATS': 2648, 'TIME': 2649, 'Testament': 2650, 'Tony': 2651, 'Um': 2652, 'W': 2653, 'WORLD': 2654, 'War': 2655, 'Watch': 2656, 'Whether': 2657, 'While': 2658, 'Wrong': 2659, \"Y'all\": 2660, 'Ya': 2661, 'accountable': 2662, 'acknowledge': 2663, 'advice': 2664, 'affected': 2665, 'amongst': 2666, 'animal': 2667, 'answers': 2668, 'aswell': 2669, 'attempt': 2670, 'awareness': 2671, 'badly': 2672, 'banned': 2673, 'became': 2674, 'bed': 2675, 'beings': 2676, 'believed': 2677, 'belly': 2678, 'blessed': 2679, 'blk': 2680, 'brains': 2681, 'breaks': 2682, 'cancer': 2683, 'caring': 2684, 'celebrating': 2685, 'circle': 2686, 'clown': 2687, 'coat': 2688, 'cold': 2689, 'collapse': 2690, 'comfortable': 2691, 'committing': 2692, 'companies': 2693, 'conspiracy': 2694, 'cross': 2695, 'crowd': 2696, 'curious': 2697, 'data': 2698, 'dating': 2699, 'dear': 2700, 'delete': 2701, 'delusional': 2702, 'demon': 2703, 'dems': 2704, 'designed': 2705, 'directly': 2706, 'divisive': 2707, 'domestic': 2708, 'donated': 2709, 'donations': 2710, 'dressed': 2711, 'dust': 2712, 'ends': 2713, 'enforcement': 2714, 'eventually': 2715, 'examples': 2716, 'existed': 2717, 'expecting': 2718, 'experienced': 2719, 'falling': 2720, 'famine': 2721, 'favorite': 2722, 'fillers': 2723, 'finger': 2724, 'finish': 2725, 'fits': 2726, 'folk': 2727, 'fox': 2728, 'freaking': 2729, 'fucked': 2730, 'funding': 2731, 'genders': 2732, 'generally': 2733, 'genocide': 2734, 'grateful': 2735, 'guarantee': 2736, 'hardly': 2737, 'health': 2738, 'hearts': 2739, 'hi': 2740, 'hiding': 2741, 'hire': 2742, 'hole': 2743, 'homes': 2744, 'hood': 2745, 'hungry': 2746, 'hypocrite': 2747, 'ill': 2748, 'indeed': 2749, 'jesus': 2750, 'juan': 2751, 'kicked': 2752, 'killings': 2753, 'leads': 2754, 'lesson': 2755, 'mainly': 2756, 'manipulate': 2757, 'manner': 2758, 'master': 2759, 'minutes': 2760, 'model': 2761, 'murderer': 2762, 'muslim': 2763, 'muslims': 2764, 'nn': 2765, 'nope': 2766, 'norm': 2767, 'nostar': 2768, 'numbers': 2769, 'offence': 2770, 'opening': 2771, 'passionate': 2772, 'patel': 2773, 'per': 2774, 'perhaps': 2775, 'pink': 2776, 'pls': 2777, 'pointless': 2778, 'pop': 2779, 'practice': 2780, 'progress': 2781, 'properly': 2782, 'pyramids': 2783, 'rally': 2784, 'ran': 2785, 'referred': 2786, 'refuse': 2787, 'regarding': 2788, 'replace': 2789, 'report': 2790, 'responding': 2791, 'retarded': 2792, 'rioting': 2793, 'sarcasm': 2794, 'scientific': 2795, 'scientist': 2796, 'scream': 2797, 'sea': 2798, 'seeking': 2799, 'sending': 2800, 'shop': 2801, 'sincere': 2802, 'sit': 2803, 'skills': 2804, 'smarter': 2805, 'socialist': 2806, 'soo': 2807, 'souls': 2808, 'space': 2809, 'starved': 2810, 'stone': 2811, 'stores': 2812, 'stronger': 2813, 'style': 2814, 'sub': 2815, 'sun': 2816, 'surgery': 2817, 'tactics': 2818, 'teen': 2819, 'theirs': 2820, 'threatened': 2821, 'threw': 2822, 'thumbs': 2823, 'tips': 2824, 'tons': 2825, 'torn': 2826, 'traditional': 2827, 'training': 2828, 'twisted': 2829, 'ugly': 2830, 'um': 2831, 'uncomfortable': 2832, 'unfairly': 2833, 'useful': 2834, 'values': 2835, 'vision': 2836, 'walked': 2837, 'wall': 2838, 'wee': 2839, 'write': 2840, '2024': 2841, '20th': 2842, '40': 2843, '4th': 2844, ';)': 2845, '@Ashley': 2846, '@Ben': 2847, '@Jake': 2848, '@Logan': 2849, '@NOXISUM': 2850, '@Sasha': 2851, '@kris': 2852, '@michael': 2853, 'ALWAYS': 2854, 'About': 2855, 'According': 2856, 'Am': 2857, 'Anonymous': 2858, 'Atlas': 2859, 'Aww': 2860, 'BEEN': 2861, 'Biden': 2862, 'Bob': 2863, 'Butt': 2864, 'COLOR': 2865, 'Canadian': 2866, 'Central': 2867, 'Check': 2868, 'Coronavirus': 2869, 'DEMOCRATS': 2870, 'DID': 2871, 'Dheas': 2872, 'Elizabeth': 2873, 'Fampionona': 2874, 'Far': 2875, 'Feminism': 2876, 'Guess': 2877, 'H': 2878, 'High': 2879, 'Humans': 2880, 'IF': 2881, 'Idiots': 2882, 'Joannot': 2883, 'Know': 2884, 'Kong': 2885, 'LIVE': 2886, 'Law': 2887, 'Live': 2888, 'London': 2889, 'MAN': 2890, 'MATTERnALL': 2891, 'Madge': 2892, 'Marxism': 2893, 'Mr.': 2894, 'Muslims': 2895, 'OTHER': 2896, 'OUT': 2897, 'P': 2898, 'Peter': 2899, 'Prove': 2900, 'RACISM': 2901, 'Real': 2902, 'Repent': 2903, 'SJW': 2904, 'Savior': 2905, 'Say': 2906, 'Shame': 2907, 'Something': 2908, 'Song': 2909, 'Spanish': 2910, 'Steve': 2911, 'TRUE': 2912, 'TV': 2913, 'TheHerpes': 2914, 'Therefore': 2915, 'Though': 2916, 'Today': 2917, 'Totally': 2918, 'Turner': 2919, 'Two': 2920, 'Until': 2921, 'Up': 2922, 'WANT': 2923, 'WAY': 2924, 'Welcome': 2925, 'Western': 2926, 'Wish': 2927, 'Wonder': 2928, 'Worenwu': 2929, 'Yea': 2930, 'advantage': 2931, 'although': 2932, 'ancient': 2933, 'anyways': 2934, 'appearance': 2935, 'area': 2936, 'art': 2937, 'arts': 2938, 'assumption': 2939, 'background': 2940, 'basic': 2941, 'begin': 2942, 'bias': 2943, 'binary': 2944, 'bitching': 2945, 'blacklivesmatter': 2946, 'blank': 2947, 'box': 2948, 'british': 2949, 'brutal': 2950, 'burned': 2951, 'cared': 2952, 'chanting': 2953, 'chick': 2954, 'childish': 2955, 'closer': 2956, 'clothes': 2957, 'clueless': 2958, 'commented': 2959, 'concern': 2960, 'conscious': 2961, 'continent': 2962, 'convinced': 2963, 'corporations': 2964, 'counter': 2965, 'courage': 2966, 'creates': 2967, 'damaging': 2968, 'dare': 2969, 'dealing': 2970, 'defined': 2971, 'demand': 2972, 'demanding': 2973, 'demands': 2974, 'dictionary': 2975, 'discouraged': 2976, 'dividing': 2977, 'dominated': 2978, 'emotions': 2979, 'era': 2980, 'event': 2981, 'explains': 2982, 'exposed': 2983, 'extra': 2984, 'fantastic': 2985, 'following': 2986, 'forgiveness': 2987, 'fuel': 2988, 'fund': 2989, 'funds': 2990, 'genuinely': 2991, 'governments': 2992, 'grade': 2993, 'guests': 2994, 'gunpoint': 2995, 'holding': 2996, 'hospitals': 2997, 'hurtful': 2998, 'hurts': 2999, 'implied': 3000, 'impossible': 3001, 'improve': 3002, 'incorrect': 3003, 'india': 3004, 'interpretation': 3005, 'invented': 3006, 'k': 3007, 'key': 3008, 'kissing': 3009, 'knees': 3010, 'l': 3011, 'label': 3012, 'labour': 3013, 'laughed': 3014, 'lazy': 3015, 'levels': 3016, 'loose': 3017, 'looted': 3018, 'losers': 3019, 'losing': 3020, 'loud': 3021, 'machine': 3022, 'market': 3023, 'mater': 3024, 'mattering': 3025, 'member': 3026, 'motives': 3027, 'nAll': 3028, 'nIt': 3029, 'nNo': 3030, 'necessarily': 3031, 'neutral': 3032, 'notion': 3033, 'nurses': 3034, 'onto': 3035, 'page': 3036, 'pants': 3037, 'paper': 3038, 'parent': 3039, 'parties': 3040, 'passion': 3041, 'percent': 3042, 'physically': 3043, 'physics': 3044, 'pity': 3045, 'planned': 3046, 'plastic': 3047, 'plus': 3048, 'politically': 3049, 'possibly': 3050, 'praying': 3051, 'previous': 3052, 'promotes': 3053, 'protecting': 3054, 'proved': 3055, 'proving': 3056, 'pursuing': 3057, 'radical': 3058, 'relationship': 3059, 'relatives': 3060, 'remind': 3061, 'reminder': 3062, 'reparations': 3063, 'reported': 3064, 'resist': 3065, 'respected': 3066, 'rise': 3067, 'rules': 3068, 'search': 3069, 'shocked': 3070, 'significant': 3071, 'six': 3072, 'smile': 3073, 'solution': 3074, 'solved': 3075, 'songs': 3076, 'spell': 3077, 'stage': 3078, 'stars': 3079, 'stating': 3080, 'store': 3081, 'sucking': 3082, 'suffered': 3083, 'sum': 3084, 'survivors': 3085, 'talkin': 3086, 'tax': 3087, 'tea': 3088, 'thy': 3089, 'ticket': 3090, 'tone': 3091, 'toppled': 3092, 'trauma': 3093, 'trend': 3094, 'tries': 3095, 'twice': 3096, 'uhhh': 3097, 'unite': 3098, 'unity': 3099, 'universe': 3100, 'university': 3101, 'usa': 3102, 'valuable': 3103, 'virtue': 3104, 'whenever': 3105, 'winning': 3106, 'worthy': 3107, 'youth': 3108, 'ðŸ¤': 3109, 'ðŸ¤¨': 3110, 'ðŸ¤©': 3111, '17': 3112, '200': 3113, '2014': 3114, '2nd': 3115, '61': 3116, '70': 3117, '80s': 3118, '@Al': 3119, '@Amazing': 3120, '@Aria': 3121, '@Bbm': 3122, '@D': 3123, '@Dangus': 3124, '@Darzo': 3125, '@Edward': 3126, '@Hippo': 3127, '@MM79': 3128, '@MrCosmin94': 3129, '@Robert': 3130, '@Tom': 3131, '@Travis': 3132, \"@it'sMe\": 3133, '@pepsi': 3134, '@xBrownskinAngelx': 3135, 'AGREE': 3136, 'AMEN': 3137, 'ANTIFA': 3138, 'Australian': 3139, 'BIG': 3140, 'Back': 3141, 'Barbie': 3142, 'Besides': 3143, 'Better': 3144, 'Bruh': 3145, 'CANT': 3146, 'Communist': 3147, 'Council': 3148, 'Dan': 3149, 'Definitely': 3150, 'Disgusting': 3151, 'Dr.': 3152, 'Dragon': 3153, 'EVERYONE': 3154, 'Egyptian': 3155, 'FOX': 3156, 'Fight': 3157, 'Gaming': 3158, 'Garcia': 3159, 'German': 3160, 'Glasgow': 3161, 'HELL': 3162, 'HELP': 3163, 'HIS': 3164, 'Hmm': 3165, 'Hong': 3166, 'I-': 3167, 'ID': 3168, 'II': 3169, 'IM': 3170, 'Idk': 3171, 'Including': 3172, 'Instead': 3173, 'JUAN': 3174, 'Jacket': 3175, 'Jamie': 3176, 'Jerde': 3177, 'KNOW': 3178, 'LOOK': 3179, 'Learn': 3180, 'Looks': 3181, 'MAKE': 3182, 'MANY': 3183, 'Make': 3184, 'Matthew': 3185, 'Maya': 3186, 'Molly': 3187, 'Music': 3188, 'NOTHING': 3189, 'Nah': 3190, 'Old': 3191, 'Over': 3192, 'PERIOD': 3193, 'POC': 3194, 'POLICE': 3195, 'Ppl': 3196, 'Prince': 3197, 'Princess': 3198, 'Proud': 3199, 'Religion': 3200, 'Roman': 3201, 'SAME': 3202, 'SHOULD': 3203, 'STUPID': 3204, 'Sam': 3205, 'Secretary': 3206, 'Sherrif': 3207, 'Shiroyuki': 3208, 'Sir': 3209, 'Slima': 3210, 'State': 3211, 'Statistics': 3212, 'Sterling': 3213, 'Stupid': 3214, 'Sweden': 3215, 'THEIR': 3216, 'Talk': 3217, 'Things': 3218, 'Timpa': 3219, 'Transgender': 3220, 'Trayvon': 3221, 'Try': 3222, 'Typical': 3223, 'UNTIL': 3224, 'Us': 3225, 'Weird': 3226, 'William': 3227, 'Without': 3228, 'Yet': 3229, 'Yo': 3230, ']': 3231, 'abolish': 3232, 'accomplish': 3233, 'accounts': 3234, 'achieve': 3235, 'ad': 3236, 'address': 3237, 'addressed': 3238, 'administration': 3239, 'aim': 3240, 'aka': 3241, 'ality': 3242, 'ally': 3243, 'angel': 3244, 'anger': 3245, 'apples': 3246, 'artists': 3247, 'asexual': 3248, 'aside': 3249, 'assumptions': 3250, 'automatically': 3251, 'avoid': 3252, 'awakening': 3253, 'awkward': 3254, 'backlash': 3255, 'backwards': 3256, 'bailey': 3257, 'banner': 3258, 'barbies': 3259, 'base': 3260, 'beaches': 3261, 'began': 3262, 'belong': 3263, 'biased': 3264, 'bitches': 3265, 'bledsoe': 3266, 'bleeding': 3267, 'block': 3268, 'bomb': 3269, 'bubble': 3270, 'bull': 3271, 'buying': 3272, 'cards': 3273, 'celebrities': 3274, 'charged': 3275, 'charity': 3276, 'chill': 3277, 'choices': 3278, 'chooses': 3279, 'christians': 3280, 'clicked': 3281, 'communists': 3282, 'concerns': 3283, 'conclusion': 3284, 'condemn': 3285, 'condemning': 3286, 'confidence': 3287, 'corruption': 3288, 'cost': 3289, 'count': 3290, 'creation': 3291, 'creator': 3292, 'crisis': 3293, 'cuffing': 3294, 'cultures': 3295, 'dealt': 3296, 'debt': 3297, 'decision': 3298, 'deeper': 3299, 'democracy': 3300, 'deserved': 3301, 'developed': 3302, 'direction': 3303, 'diverse': 3304, 'door': 3305, 'drag': 3306, 'dresses': 3307, 'dumbest': 3308, 'easier': 3309, 'ego': 3310, 'eh': 3311, 'electrical': 3312, 'embrace': 3313, 'empathy': 3314, 'encouraging': 3315, 'ending': 3316, 'equals': 3317, 'expected': 3318, 'extremist': 3319, 'faces': 3320, 'facing': 3321, 'factors': 3322, 'fame': 3323, 'fascist': 3324, 'fingers': 3325, 'flag': 3326, 'flat': 3327, 'focused': 3328, 'fooled': 3329, 'forgetting': 3330, 'freak': 3331, 'gap': 3332, 'giant': 3333, 'grandparents': 3334, 'guessing': 3335, 'harbour': 3336, 'heads': 3337, 'heck': 3338, 'herd': 3339, 'highest': 3340, 'homophobes': 3341, 'honey': 3342, 'honor': 3343, 'honored': 3344, 'hypocrites': 3345, 'immigrants': 3346, 'immoral': 3347, 'incident': 3348, 'incredibly': 3349, 'independent': 3350, 'info': 3351, 'insecure': 3352, 'insulting': 3353, 'intellectual': 3354, 'jacket': 3355, 'jewish': 3356, 'jokes': 3357, 'judgement': 3358, 'jumping': 3359, 'killer': 3360, 'kneel': 3361, 'led': 3362, 'lifestyle': 3363, 'lip': 3364, 'lmfao': 3365, 'looters': 3366, 'lord': 3367, 'lovely': 3368, 'march': 3369, 'meeting': 3370, 'meme': 3371, 'mess': 3372, 'mix': 3373, 'moral': 3374, 'nBlack': 3375, 'nThis': 3376, 'nWhat': 3377, 'nand': 3378, 'national': 3379, 'nationality': 3380, 'ngl': 3381, 'nnLike': 3382, 'nuts': 3383, 'opposing': 3384, 'organizations': 3385, 'overall': 3386, 'particular': 3387, 'pass': 3388, 'pigs': 3389, 'pill': 3390, 'piss': 3391, 'plantation': 3392, 'politician': 3393, 'portion': 3394, 'premise': 3395, 'presidency': 3396, 'prime': 3397, 'professional': 3398, 'professor': 3399, 'proper': 3400, 'publicly': 3401, 'punished': 3402, 'qualified': 3403, 'quality': 3404, 'questioned': 3405, 'quickly': 3406, 'racially': 3407, 'random': 3408, 'refer': 3409, 'refreshing': 3410, 'ruining': 3411, 'scam': 3412, 'screen': 3413, 'seek': 3414, 'senior': 3415, 'separated': 3416, 'sherrif': 3417, 'silly': 3418, 'smell': 3419, 'sources': 3420, 'south': 3421, 'speaker': 3422, 'statistically': 3423, 'staying': 3424, 'stem': 3425, 'stepped': 3426, 'stereotypical': 3427, 'stole': 3428, 'straw': 3429, 'subscribed': 3430, 'success': 3431, 'supremacist': 3432, 'symbol': 3433, 'target': 3434, 'team': 3435, 'teeth': 3436, 'tend': 3437, 'thankful': 3438, 'thug': 3439, 'tiny': 3440, 'tool': 3441, 'topics': 3442, 'trading': 3443, 'trolling': 3444, 'trumps': 3445, 'typical': 3446, 'unit': 3447, 'unjustly': 3448, 'unlike': 3449, 'useless': 3450, 'vast': 3451, 'versus': 3452, 'walking': 3453, 'warrior': 3454, 'wars': 3455, 'weakness': 3456, 'wishes': 3457, 'worried': 3458, 'writing': 3459, 'yourselves': 3460, 'yr': 3461, 'ðŸ§': 3462, '..........': 3463, '._.': 3464, '0': 3465, '12894': 3466, '2.0': 3467, '2000': 3468, '300': 3469, '<': 3470, '@Aaron': 3471, '@Anthony': 3472, '@Beautiful': 3473, '@Darren': 3474, '@Jason': 3475, '@Jun3': 3476, '@Khaver': 3477, '@Matthew': 3478, '@Pretend': 3479, '@S.': 3480, '@Troy': 3481, '@Vanesa': 3482, '@Vernice': 3483, '@Zero': 3484, '@mya': 3485, '@pagan': 3486, '@say': 3487, '@you': 3488, 'AGAINST': 3489, 'AKA': 3490, 'Aaron': 3491, 'Alright': 3492, 'Anti': 3493, 'April': 3494, 'Atlantic': 3495, 'Australia': 3496, 'Awesome': 3497, 'BABIES': 3498, 'BEFORE': 3499, 'BEST': 3500, 'BTW': 3501, 'Baden': 3502, 'Beating': 3503, 'Believe': 3504, 'Bennett': 3505, 'Born': 3506, 'Brilliant': 3507, 'CHANGE': 3508, 'Children': 3509, 'Chloe': 3510, 'Collins': 3511, 'Congratulations': 3512, 'Conservative': 3513, 'Country': 3514, 'Danielle': 3515, 'Dave': 3516, 'Dem': 3517, 'Don': 3518, 'EXACTLY': 3519, 'Either': 3520, 'Emily': 3521, 'FUCKING': 3522, 'Fake': 3523, 'Father': 3524, 'Female': 3525, 'Feminist': 3526, 'Frank': 3527, 'Fuck': 3528, 'Gandhi': 3529, 'Gay': 3530, 'Gerrard': 3531, 'Greek': 3532, 'Guy': 3533, 'HEART': 3534, 'HUMAN': 3535, 'Hahaha': 3536, 'Harris': 3537, 'Has': 3538, 'Hell': 3539, 'Hello': 3540, 'Him': 3541, 'I.': 3542, 'Inspiring': 3543, 'Jews': 3544, 'July': 3545, 'Karen': 3546, 'Kay': 3547, 'Kid': 3548, 'Kinda': 3549, 'Knight': 3550, 'LA': 3551, 'LAST': 3552, 'LEFT': 3553, 'LESBIAN': 3554, 'LET': 3555, 'Last': 3556, 'Latinos': 3557, 'Lavin': 3558, 'Legend': 3559, 'Lilyx': 3560, 'Lion': 3561, 'Looking': 3562, 'Lynch': 3563, 'MUST': 3564, 'Maggie': 3565, 'Malcolm': 3566, 'Marie': 3567, 'Mcfadyen': 3568, 'Mexico': 3569, 'Morgan': 3570, 'Musso': 3571, 'Must': 3572, 'Noah': 3573, 'Nope': 3574, 'OH': 3575, 'Order': 3576, 'PR': 3577, 'Palestinian': 3578, 'Paver': 3579, 'Period': 3580, 'Politics': 3581, 'Poor': 3582, 'Power': 3583, 'Presbyterian': 3584, 'Putin': 3585, 'REALLY': 3586, 'RL': 3587, 'Rainbow': 3588, 'Regardless': 3589, 'Rice': 3590, 'Robinson': 3591, 'Romans': 3592, 'Royalty': 3593, 'SAID': 3594, 'SJWs': 3595, 'SKIN': 3596, 'SOME': 3597, 'STILL': 3598, 'Soul': 3599, 'Statues': 3600, 'Stephanie': 3601, 'THEN': 3602, 'THESE': 3603, 'Trying': 3604, 'Unarmed': 3605, 'Virus': 3606, 'WELL': 3607, 'WERE': 3608, 'WOULD': 3609, 'WTF': 3610, 'Word': 3611, 'Yay': 3612, 'Yellow': 3613, 'Yip': 3614, 'York': 3615, 'abortions': 3616, 'abusive': 3617, 'acceptable': 3618, 'accepts': 3619, 'activists': 3620, 'admire': 3621, 'affirmative': 3622, 'ah': 3623, 'amen': 3624, 'anarchy': 3625, 'annoyed': 3626, 'antifa': 3627, 'applied': 3628, 'appreciated': 3629, 'approach': 3630, 'areas': 3631, 'asses': 3632, 'assumed': 3633, 'atleast': 3634, 'attend': 3635, 'attraction': 3636, 'authority': 3637, 'beer': 3638, 'benefit': 3639, 'bigot': 3640, 'billion': 3641, 'bitch': 3642, 'blah': 3643, 'blocks': 3644, 'bloody': 3645, 'blowing': 3646, 'blown': 3647, 'boss': 3648, 'bristol': 3649, 'bros': 3650, 'busy': 3651, 'button': 3652, 'butts': 3653, 'bye': 3654, 'capitalism': 3655, 'careers': 3656, 'carry': 3657, 'catch': 3658, 'celebrate': 3659, 'celebrated': 3660, 'center': 3661, 'checked': 3662, 'childhood': 3663, 'christianity': 3664, 'cis': 3665, 'civilization': 3666, 'clarke': 3667, 'closely': 3668, 'colored': 3669, 'colston': 3670, 'commenting': 3671, 'communism': 3672, 'compare': 3673, 'compassionate': 3674, 'complex': 3675, 'concert': 3676, 'conditions': 3677, 'consequences': 3678, 'constant': 3679, 'convince': 3680, 'corner': 3681, 'correctness': 3682, 'cough': 3683, 'cousin': 3684, 'crack': 3685, 'crush': 3686, 'cure': 3687, 'custody': 3688, 'daddy': 3689, 'danger': 3690, 'define': 3691, 'demonstrations': 3692, 'denying': 3693, 'develop': 3694, 'dictate': 3695, 'dirty': 3696, 'disappear': 3697, 'discuss': 3698, 'disguise': 3699, 'dismiss': 3700, 'disparity': 3701, 'disproportionately': 3702, 'distroy': 3703, 'don': 3704, 'drive': 3705, 'earlier': 3706, 'earn': 3707, 'emotion': 3708, 'empire': 3709, 'endless': 3710, 'enemies': 3711, 'established': 3712, 'evening': 3713, 'events': 3714, 'ex': 3715, 'excessive': 3716, 'excluding': 3717, 'exclusive': 3718, 'explained': 3719, 'extremists': 3720, 'failing': 3721, 'fairly': 3722, 'fast': 3723, 'feed': 3724, 'fighter': 3725, 'film': 3726, 'finest': 3727, 'fixed': 3728, 'forces': 3729, 'forgive': 3730, 'fortunate': 3731, 'founded': 3732, 'friendly': 3733, 'fucken': 3734, 'fuckin': 3735, 'fucks': 3736, 'g': 3737, 'german': 3738, 'gold': 3739, 'graduate': 3740, 'graduated': 3741, 'green': 3742, 'grey': 3743, 'gunned': 3744, 'handle': 3745, 'handled': 3746, 'hannity': 3747, 'headed': 3748, 'heartfelt': 3749, 'heavily': 3750, 'hijacked': 3751, 'hitler': 3752, 'hitting': 3753, 'hopefully': 3754, 'household': 3755, 'humble': 3756, 'hundred': 3757, 'icon': 3758, 'illness': 3759, 'impressed': 3760, 'income': 3761, 'increase': 3762, 'inequality': 3763, 'infected': 3764, 'informed': 3765, 'inner': 3766, 'insults': 3767, 'interests': 3768, 'invalid': 3769, 'invent': 3770, 'ironic': 3771, 'jealous': 3772, 'journey': 3773, 'jr': 3774, 'kahlo': 3775, 'kingdom': 3776, 'lands': 3777, 'latino': 3778, 'leading': 3779, 'lefties': 3780, 'legacy': 3781, 'legends': 3782, 'legs': 3783, 'liar': 3784, 'lied': 3785, 'lips': 3786, 'loads': 3787, 'luv': 3788, 'majors': 3789, 'marketing': 3790, 'married': 3791, 'marxist': 3792, 'marxists': 3793, 'masculine': 3794, 'masses': 3795, 'mirror': 3796, 'mistaken': 3797, 'mood': 3798, 'moronic': 3799, 'mouths': 3800, 'multicultural': 3801, 'nBut': 3802, 'nHe': 3803, 'nah': 3804, 'nail': 3805, 'nelson': 3806, 'net': 3807, 'nnAnd': 3808, 'obama': 3809, 'online': 3810, 'option': 3811, 'orders': 3812, 'outrage': 3813, 'overly': 3814, 'painting': 3815, 'pedophilia': 3816, 'peers': 3817, 'picking': 3818, 'pissed': 3819, 'pisses': 3820, 'planning': 3821, 'policeman': 3822, 'popular': 3823, 'posting': 3824, 'prepared': 3825, 'presented': 3826, 'prevent': 3827, 'priest': 3828, 'product': 3829, 'professions': 3830, 'profiling': 3831, 'proves': 3832, 'puppet': 3833, 'purposefully': 3834, 'puts': 3835, 'quiet': 3836, 'quo': 3837, 'recording': 3838, 'records': 3839, 'removing': 3840, 'repeating': 3841, 'replied': 3842, 'replying': 3843, 'responsibility': 3844, 'return': 3845, 'reward': 3846, 'risking': 3847, 'ruin': 3848, 'saves': 3849, 'savior': 3850, 'scale': 3851, 'script': 3852, 'scripture': 3853, 'scriptures': 3854, 'seconds': 3855, 'segregating': 3856, 'selves': 3857, 'separation': 3858, 'sh*t': 3859, 'shameful': 3860, 'shapes': 3861, 'sherif': 3862, 'shitty': 3863, 'shooting': 3864, 'shoulders': 3865, 'signalling': 3866, 'signed': 3867, 'silent': 3868, 'silver': 3869, 'sing': 3870, 'skill': 3871, 'skinny': 3872, 'slogans': 3873, 'soldiers': 3874, 'spent': 3875, 'spring': 3876, 'stance': 3877, 'starving': 3878, 'stealing': 3879, 'sue': 3880, 'sugar': 3881, 'suggest': 3882, 'suit': 3883, 'suits': 3884, 'supportive': 3885, 'surprise': 3886, 'technical': 3887, 'ten': 3888, 'terrorism': 3889, 'test': 3890, 'thay': 3891, 'thus': 3892, 'thx': 3893, 'tj': 3894, 'tomboy': 3895, 'touching': 3896, 'towns': 3897, 'toxic': 3898, 'tragic': 3899, 'trigger': 3900, 'tv': 3901, 'undermining': 3902, 'uniform': 3903, 'unique': 3904, 'unnecessary': 3905, 'usual': 3906, 'vibes': 3907, 'viewpoint': 3908, 'wage': 3909, 'warriors': 3910, 'weather': 3911, 'weekend': 3912, 'whatsoever': 3913, 'whom': 3914, 'wild': 3915, 'workforce': 3916, 'workplace': 3917, 'worthless': 3918, 'wrongly': 3919, 'yell': 3920, 'yesterday': 3921, 'yrs': 3922, '~': 3923, 'ðŸ§¡': 3924, '1000': 3925, '129': 3926, '16': 3927, '1990': 3928, '21st': 3929, '29': 3930, '@*It': 3931, '@Alligator': 3932, '@Andrew21795': 3933, '@Andy': 3934, '@B': 3935, '@BJGvideos': 3936, '@CaptinOD': 3937, '@Carola': 3938, '@Donâ€™t': 3939, '@Eagle': 3940, '@Gaz': 3941, '@Grip': 3942, '@Harverc': 3943, '@Jesus': 3944, '@Joshua': 3945, '@Nick': 3946, '@Paul': 3947, '@Red': 3948, '@Sam': 3949, '@Stephanie': 3950, '@TheCounterpointer': 3951, '@martini': 3952, '@ozzie': 3953, '@rgw1380rw': 3954, '@super': 3955, '@thomas': 3956, 'AGAIN': 3957, 'ALSO': 3958, 'ANYONE': 3959, 'AWESOME': 3960, 'Abandon': 3961, 'Afro': 3962, 'Al': 3963, 'Amadeus': 3964, 'Andrew': 3965, 'Arab': 3966, 'Ass': 3967, 'Atheist': 3968, 'BELIEVE': 3969, 'BOSS': 3970, 'BROWN': 3971, 'Baltimore': 3972, 'Bear': 3973, 'Ben': 3974, 'Best': 3975, 'Bet': 3976, 'Birukov': 3977, 'Bisexual': 3978, 'BlackLivesMatter': 3979, 'Blake': 3980, 'Boris': 3981, 'Boy': 3982, 'Btw': 3983, 'Bush': 3984, 'Buster': 3985, 'CCP': 3986, 'CHILDREN': 3987, 'CLINTON': 3988, 'COUNTRY': 3989, 'COVID-19': 3990, 'Cats999': 3991, 'Chris': 3992, 'Colvin': 3993, 'Coming': 3994, 'Congressional': 3995, 'Cop': 3996, 'Corona': 3997, 'Covid19': 3998, 'Crime': 3999, 'DNA': 4000, 'DOWN': 4001, 'Dorn': 4002, 'Doty': 4003, 'Dumb': 4004, 'Dus': 4005, 'EACH': 4006, 'EVIL': 4007, 'Edwards': 4008, 'Egypt': 4009, 'Egyptians': 4010, 'Empire': 4011, 'Epic': 4012, 'Eurovision': 4013, 'Eve': 4014, 'Exodus': 4015, 'Fact': 4016, 'Facts': 4017, 'Find': 4018, 'Fish': 4019, 'Freedom': 4020, 'GENOCIDE': 4021, 'GIVE': 4022, 'GODS': 4023, 'Gaga': 4024, 'Giving': 4025, 'GoldieBlox': 4026, 'Grace': 4027, 'Guys': 4028, 'HER': 4029, 'HERE': 4030, 'Happy': 4031, 'Having': 4032, 'Heart': 4033, 'Hmmm': 4034, 'Home': 4035, 'Hum': 4036, 'Hypocrisy': 4037, \"I'M\": 4038, 'IGNORANT': 4039, 'ISRAEL': 4040, 'Ice': 4041, 'Industrial': 4042, 'Injustice': 4043, 'Ironic': 4044, 'Jesse': 4045, 'Jim': 4046, 'KID': 4047, 'KING': 4048, 'Karl': 4049, 'Kelly': 4050, 'LGBTQIA+': 4051, 'Latino': 4052, 'Lego': 4053, 'Liberalism': 4054, 'Lies': 4055, 'Lyon': 4056, 'M.': 4057, 'MEAN': 4058, 'Makes': 4059, 'Male': 4060, 'Mandela': 4061, 'Maria': 4062, 'Mason': 4063, 'Maui': 4064, 'Meanwhile': 4065, 'Mexicans': 4066, 'Milwaukee': 4067, 'Mind': 4068, 'MultiDarkZen': 4069, 'NEEDS': 4070, 'NOM': 4071, 'NRA': 4072, 'Nosferatu': 4073, 'Officer': 4074, 'Otherwise': 4075, 'PERSON': 4076, 'Pandering': 4077, 'Part': 4078, 'Pathetic': 4079, 'Pearn': 4080, 'Personally': 4081, 'Prime': 4082, 'Pure': 4083, 'Q': 4084, 'QUEEN': 4085, 'RIP': 4086, 'Racists': 4087, 'Randall': 4088, 'Ray': 4089, 'Religious': 4090, 'Removing': 4091, 'Riviera': 4092, 'Rock': 4093, 'SUPPORT': 4094, 'Sandberg': 4095, 'Save': 4096, 'Seattle': 4097, 'Selassie': 4098, 'Silicon': 4099, 'Sounds': 4100, 'Spot': 4101, 'Stand': 4102, 'Story': 4103, 'SÃNCHEZ': 4104, 'THINGS': 4105, 'THINK': 4106, 'THOUGHT': 4107, 'Theo': 4108, 'Thompson': 4109, 'Tom': 4110, 'Tosh': 4111, 'USED': 4112, 'University': 4113, 'V': 4114, 'WW3': 4115, 'Were': 4116, 'Whenever': 4117, 'Whitaker': 4118, 'Wise': 4119, 'Woman': 4120, 'Year': 4121, 'Years': 4122, 'Zara': 4123, 'Zolik': 4124, '[': 4125, 'abhorrent': 4126, 'aborted': 4127, 'absurd': 4128, 'abt': 4129, 'accent': 4130, 'accurate': 4131, 'acknowledging': 4132, 'addressing': 4133, 'adopt': 4134, 'af': 4135, 'afford': 4136, 'aged': 4137, 'aggressive': 4138, 'agrees': 4139, 'air': 4140, 'al': 4141, 'allowing': 4142, 'allows': 4143, 'amendment': 4144, 'anytime': 4145, 'appear': 4146, 'apple': 4147, 'arresting': 4148, 'asia': 4149, 'associate': 4150, 'atm': 4151, 'attempting': 4152, 'awake': 4153, 'badge': 4154, 'ban': 4155, 'bang': 4156, 'barbie': 4157, 'barely': 4158, 'beauty': 4159, 'behalf': 4160, 'besides': 4161, 'bigoted': 4162, 'bird': 4163, 'birds': 4164, 'board': 4165, 'borders': 4166, 'brexit': 4167, 'bright': 4168, 'broke': 4169, 'buddy': 4170, 'bullying': 4171, 'careful': 4172, 'cash': 4173, 'cast': 4174, 'caucasians': 4175, 'celebration': 4176, 'chain': 4177, 'challenge': 4178, 'chances': 4179, 'charities': 4180, 'chat': 4181, 'choosing': 4182, 'citizen': 4183, 'classic': 4184, 'clean': 4185, 'clip': 4186, 'closed': 4187, 'colonial': 4188, 'coloured': 4189, 'comfort': 4190, 'comparison': 4191, 'computers': 4192, 'confident': 4193, 'conflict': 4194, 'congratulations': 4195, 'contrary': 4196, 'contraversial': 4197, 'convicted': 4198, 'corporate': 4199, 'correctly': 4200, 'cos': 4201, 'costs': 4202, 'coz': 4203, 'creative': 4204, 'crown': 4205, 'cult': 4206, 'dam': 4207, 'damned': 4208, 'dance': 4209, 'daughters': 4210, 'david': 4211, 'decisions': 4212, 'defensive': 4213, 'deliver': 4214, 'department': 4215, 'depends': 4216, 'described': 4217, 'desperately': 4218, 'despicable': 4219, 'digging': 4220, 'discriminate': 4221, 'discriminating': 4222, 'discussing': 4223, 'disease': 4224, 'disgust': 4225, 'display': 4226, 'distraction': 4227, 'dosent': 4228, 'doubting': 4229, 'drama': 4230, 'dreams': 4231, 'driving': 4232, 'drop': 4233, 'dumbed': 4234, 'economic': 4235, 'elder': 4236, 'em': 4237, 'enlightened': 4238, 'ethnicity': 4239, 'evils': 4240, 'excellent': 4241, 'excited': 4242, 'fabrics': 4243, 'fails': 4244, 'failure': 4245, 'farmers': 4246, 'feeding': 4247, 'feet': 4248, 'fights': 4249, 'financial': 4250, 'finds': 4251, 'fist': 4252, 'focuses': 4253, 'followers': 4254, 'forcing': 4255, 'foreign': 4256, 'fraud': 4257, 'gains': 4258, 'games': 4259, 'gift': 4260, 'globally': 4261, 'globe': 4262, 'goals': 4263, 'gotcha': 4264, 'grandchildren': 4265, 'greatly': 4266, 'grip': 4267, 'hang': 4268, 'healthy': 4269, 'heat': 4270, 'heroes': 4271, 'hilarious': 4272, 'hiring': 4273, 'holds': 4274, 'homeless': 4275, 'hoping': 4276, 'horror': 4277, 'hour': 4278, 'hun': 4279, 'idols': 4280, 'ikr': 4281, 'illuminati': 4282, 'imagination': 4283, 'imma': 4284, 'immature': 4285, 'immigrant': 4286, 'impact': 4287, 'incompetent': 4288, 'indian': 4289, 'indoctrinated': 4290, 'institutions': 4291, 'intent': 4292, 'invasion': 4293, 'irrelevant': 4294, 'isis': 4295, 'jackson': 4296, 'judgmental': 4297, 'jules': 4298, 'karma': 4299, 'labeled': 4300, 'labor': 4301, 'lately': 4302, 'lecture': 4303, 'letter': 4304, 'lil': 4305, 'limited': 4306, 'listed': 4307, 'll': 4308, 'locked': 4309, 'logical': 4310, 'loot': 4311, 'loss': 4312, 'lower': 4313, 'madness': 4314, 'mainstream': 4315, 'mankind': 4316, 'mans': 4317, 'masters': 4318, 'maths': 4319, 'mayor': 4320, 'meee': 4321, 'melanin': 4322, 'memes': 4323, 'mens': 4324, 'merely': 4325, 'messages': 4326, 'mic': 4327, 'mis': 4328, 'mission': 4329, 'misunderstanding': 4330, 'monster': 4331, 'morals': 4332, 'morning': 4333, 'mothers': 4334, 'motivated': 4335, 'mr': 4336, 'mum': 4337, 'nIf': 4338, 'nThat': 4339, 'nWhy': 4340, 'nailed': 4341, 'naive': 4342, 'narcissistic': 4343, 'nasty': 4344, 'nationalities': 4345, 'natives': 4346, 'neighbor': 4347, 'network': 4348, 'nit': 4349, 'nnIt': 4350, 'nnThe': 4351, 'nnWhat': 4352, 'nnnBlack': 4353, 'norms': 4354, 'north': 4355, 'nose': 4356, 'note': 4357, 'novel': 4358, 'ofaboosting': 4359, 'offends': 4360, 'officials': 4361, 'olds': 4362, 'openly': 4363, 'oppress': 4364, 'options': 4365, 'organizers': 4366, 'ought': 4367, 'outlets': 4368, 'outta': 4369, 'pander': 4370, 'panel': 4371, 'paycheck': 4372, 'pays': 4373, 'perceived': 4374, 'perception': 4375, 'perpetuate': 4376, 'phone': 4377, 'pic': 4378, 'pictured': 4379, 'pixie': 4380, 'poison': 4381, 'policies': 4382, 'posts': 4383, 'preach': 4384, 'preaching': 4385, 'predominantly': 4386, 'princesses': 4387, 'priti': 4388, 'prize': 4389, 'productive': 4390, 'profit': 4391, 'programs': 4392, 'projects': 4393, 'promise': 4394, 'promises': 4395, 'proportion': 4396, 'protection': 4397, 'puppets': 4398, 'questioning': 4399, 'quick': 4400, 'racest': 4401, 'radiates': 4402, 'rasist': 4403, 'rates': 4404, 'ratio': 4405, 'raw': 4406, 'realizes': 4407, 'received': 4408, 'recognize': 4409, 'relations': 4410, 'relationships': 4411, 'released': 4412, 'respond': 4413, 'results': 4414, 'retired': 4415, 'reverse': 4416, 'rewrite': 4417, 'roles': 4418, 'roll': 4419, 'root': 4420, 's.': 4421, 'safety': 4422, 'sales': 4423, 'sang': 4424, 'satan': 4425, 'sauce': 4426, 'scenes': 4427, 'semester': 4428, 'seriouslynnThis': 4429, 'setting': 4430, 'sex': 4431, 'sheriffs': 4432, 'shirts': 4433, 'shops': 4434, 'signal': 4435, 'silence': 4436, 'situations': 4437, 'sleep': 4438, 'snowflakes': 4439, 'socialism': 4440, 'solid': 4441, 'sooner': 4442, 'soooo': 4443, 'stolen': 4444, 'stream': 4445, 'stretch': 4446, 'struggles': 4447, 'struggling': 4448, 'sued': 4449, 'suggesting': 4450, 'suggests': 4451, 'sums': 4452, 'suspicious': 4453, 'switched': 4454, 'systematically': 4455, 'table': 4456, 'tape': 4457, 'teaches': 4458, 'technically': 4459, 'teenager': 4460, 'terror': 4461, 'text': 4462, 'theme': 4463, 'thomas': 4464, 'throat': 4465, 'thrown': 4466, 'thru': 4467, 'thumbnail': 4468, 'tomorrow': 4469, 'toppling': 4470, 'tour': 4471, 'toward': 4472, 'treatment': 4473, 'treats': 4474, 'tribe': 4475, 'tryin': 4476, 'tryna': 4477, 'turtles': 4478, 'twitter': 4479, 'tyranny': 4480, 'uhh': 4481, 'undermines': 4482, 'unfair': 4483, 'ungrateful': 4484, 'united': 4485, 'upper': 4486, 'username': 4487, 'verse': 4488, 'verses': 4489, 'victimized': 4490, 'vile': 4491, 'voters': 4492, 'wash': 4493, 'weed': 4494, 'whining': 4495, 'wide': 4496, 'wins': 4497, 'wired': 4498, 'wisdom': 4499, 'womans': 4500, 'worshippers': 4501, 'yelling': 4502, 'yâ€™allnnthats': 4503, '\\xa0\\xa0 ': 4504, 'â€¢': 4505, 'ðŸ¤¢': 4506, 'ðŸ¤­': 4507, '     ': 4508, '      ': 4509, '       ': 4510, '.........': 4511, '/pol/': 4512, '110': 4513, '120': 4514, '123': 4515, '150': 4516, '167': 4517, '2005': 4518, '2017': 4519, '2018': 4520, '50/50': 4521, '500': 4522, '6th': 4523, '77': 4524, '777': 4525, '800': 4526, '8chan': 4527, '95': 4528, '97': 4529, '@2020': 4530, '@Abrams': 4531, '@Adam': 4532, '@Andrew': 4533, '@Ashxr': 4534, '@Be': 4535, '@Bobby': 4536, '@Brian': 4537, '@Callie': 4538, '@Claire': 4539, '@Clayface': 4540, '@Damian': 4541, '@Daniel': 4542, '@Denise': 4543, '@Doc': 4544, '@Emily': 4545, '@FF8WasTheBestFF': 4546, '@Fear': 4547, '@Frederick': 4548, '@Grizzly': 4549, '@Hello': 4550, '@ImAlfie': 4551, '@Imogen': 4552, '@Indiana': 4553, '@Insidious': 4554, '@Kappy': 4555, '@Kurt': 4556, '@Max': 4557, '@Miles': 4558, '@Morgan': 4559, '@MrMojoman1236': 4560, '@Neet': 4561, '@Nicholas': 4562, '@No': 4563, '@Pho': 4564, '@Ryan': 4565, '@Samuel': 4566, '@Shawn': 4567, '@Skylight': 4568, '@Starchild': 4569, '@TOJO': 4570, '@Tea': 4571, '@That': 4572, '@Tim': 4573, '@Trent': 4574, '@TuNe': 4575, '@Urban': 4576, '@Zach': 4577, '@aussiebear22': 4578, '@be': 4579, '@bluefavorites': 4580, '@everett': 4581, '@gamerxj': 4582, '@hello': 4583, '@hexapositive': 4584, '@jmal': 4585, '@mi': 4586, '@mike': 4587, '@oomz1975': 4588, '@openworld': 4589, '@stick': 4590, '@tadhg': 4591, '@teleshit': 4592, '@the': 4593, '@ur': 4594, 'A.': 4595, 'A.J': 4596, 'AMERICANS': 4597, 'ANYBODY': 4598, 'Aless': 4599, 'AllLivesMatter': 4600, 'Although': 4601, 'Amy': 4602, 'Ancient': 4603, 'Angel': 4604, 'Answer': 4605, 'Anybody': 4606, 'Army': 4607, 'Around': 4608, 'Aw': 4609, 'BILL': 4610, 'BLMs': 4611, 'BLm': 4612, 'BOOK': 4613, 'BOY': 4614, 'Babies': 4615, 'Bbm': 4616, 'Beckett': 4617, 'Benchekroun': 4618, 'Beyonce': 4619, 'Blame': 4620, 'Boet': 4621, 'Boredom': 4622, 'Bravo': 4623, 'Brazil': 4624, 'Britian': 4625, 'Buffalo': 4626, 'CHILD': 4627, 'CHRIST': 4628, 'CK': 4629, 'COMMENT': 4630, 'COMMUNITY': 4631, 'COURSE': 4632, 'COVID': 4633, 'CRY': 4634, 'CUFFED': 4635, 'CUTE': 4636, 'Call': 4637, 'Calm': 4638, 'Campbell': 4639, 'Capitalism': 4640, 'Caucasians': 4641, 'Cc': 4642, 'Chemical': 4643, 'Chief': 4644, 'Christmas': 4645, 'City': 4646, 'Classic': 4647, 'Cobb': 4648, 'Criminal': 4649, 'Cultural': 4650, 'DAVID': 4651, 'DIFFERENT': 4652, 'DR': 4653, 'Dad': 4654, 'Darryl': 4655, 'Depends': 4656, 'Derp': 4657, 'Destroying': 4658, 'Disgraceful': 4659, 'Driscoll': 4660, 'ELSE': 4661, 'END': 4662, 'ERIC': 4663, 'EU': 4664, 'Electrical': 4665, 'Eloise': 4666, 'Enough': 4667, 'Eugene': 4668, 'Excuse': 4669, 'F.': 4670, 'Fair': 4671, 'Family': 4672, 'Farage': 4673, 'Females': 4674, 'Fernandes': 4675, 'Fighting': 4676, 'Follow': 4677, 'Forget': 4678, 'Fortnut2821': 4679, 'Fran': 4680, 'Free': 4681, 'Freek': 4682, 'Full': 4683, 'GG': 4684, 'GOT': 4685, 'GROUP': 4686, 'GUESS': 4687, 'Glad': 4688, 'Going': 4689, 'Gon': 4690, 'Green': 4691, 'Gregory': 4692, 'Griffith': 4693, 'Grow': 4694, 'Guo': 4695, 'Half': 4696, 'Halligan': 4697, 'Harvey': 4698, 'Heather': 4699, 'Help': 4700, 'Hi': 4701, 'HiRAEth': 4702, 'Hilary': 4703, 'Hill': 4704, 'Himmelright': 4705, 'Hindu': 4706, 'Hippo': 4707, 'Historic': 4708, 'HitorÄ': 4709, 'Hold': 4710, 'Homophobia': 4711, 'Howard': 4712, 'Huh': 4713, 'Hussein': 4714, 'Hypocrite': 4715, 'INTO': 4716, 'IQ': 4717, 'Idiot': 4718, 'Ill': 4719, 'Indeed': 4720, 'Indiana': 4721, 'Innocent': 4722, 'Inzodda': 4723, 'Istanbul': 4724, 'J.': 4725, 'Jan': 4726, 'Jason': 4727, 'Jasper': 4728, 'Jaun': 4729, 'Jeff': 4730, 'Joseph': 4731, 'Jr.': 4732, 'KIDS': 4733, 'KILLED': 4734, 'KKK': 4735, 'Kabbalist': 4736, 'Kat': 4737, 'Kenny': 4738, 'Kings': 4739, 'Knowitall': 4740, 'Korea': 4741, 'Korean': 4742, 'LESS': 4743, 'LIES': 4744, 'LITERALLY': 4745, 'Lady': 4746, 'Lauper': 4747, 'Leftist': 4748, 'Lehman': 4749, 'Lemon': 4750, 'Lesbian': 4751, 'Leviticus': 4752, 'Levry': 4753, 'Libya': 4754, 'Lincoln': 4755, 'Little': 4756, 'Littler': 4757, 'Lockhart': 4758, 'Lonnie': 4759, 'Lothbrok': 4760, 'Lovely': 4761, 'Loving': 4762, 'Lynn': 4763, 'MJ': 4764, 'MOST': 4765, 'MP': 4766, 'MUCH': 4767, 'Males': 4768, 'Mario': 4769, 'Mark': 4770, 'Marx': 4771, 'Materia': 4772, 'Mattering': 4773, 'Mc': 4774, 'Mechanical': 4775, 'Mia': 4776, 'Micheal': 4777, 'Minister': 4778, 'Moorish': 4779, 'Move': 4780, 'Mugabe': 4781, 'Mugieq': 4782, 'Muhammad': 4783, 'Mulenga': 4784, 'NWO': 4785, 'Nathanael': 4786, 'National': 4787, 'Nazi': 4788, 'Need': 4789, 'Neither': 4790, 'Neo': 4791, 'Nina': 4792, 'Noelle': 4793, 'North': 4794, 'Nova': 4795, 'November': 4796, 'OVER': 4797, 'Open': 4798, 'Other': 4799, 'PATTYY': 4800, 'PC': 4801, 'POINT': 4802, 'POLITICS': 4803, 'PRAY': 4804, 'PRESIDENT': 4805, 'Palestinians': 4806, 'Pan': 4807, 'Parenthood': 4808, 'Parliament': 4809, 'Peace': 4810, 'Perfect': 4811, 'Perhaps': 4812, 'PhD': 4813, 'Pitner': 4814, 'Pollack': 4815, 'Privilege': 4816, 'Proof': 4817, 'Ps': 4818, 'Psychic': 4819, 'Question': 4820, 'RACISTS': 4821, 'REMEMBER': 4822, 'RESPECT': 4823, 'Racial': 4824, 'Radical': 4825, 'Remove': 4826, 'Replace': 4827, 'Rich': 4828, 'Rizki': 4829, 'Rob': 4830, 'Rome': 4831, 'Ron': 4832, 'Ross': 4833, 'SAYING': 4834, 'STAN': 4835, 'Samurai': 4836, 'Sandra': 4837, 'Sarkar': 4838, 'Satanist': 4839, 'Sean': 4840, 'Search': 4841, 'Second': 4842, 'Seeing': 4843, 'Seems': 4844, 'Segregation': 4845, 'Short': 4846, 'Sis': 4847, 'Six': 4848, 'Skate': 4849, 'Skin': 4850, 'Social': 4851, 'Socialist': 4852, 'Somebody': 4853, 'Somehow': 4854, 'Stark': 4855, 'Start': 4856, 'Stephen': 4857, 'Stevens': 4858, 'Storey': 4859, 'Stuff': 4860, 'Summer': 4861, 'Supremacy': 4862, 'Swedish': 4863, 'THINKING': 4864, 'THUGS': 4865, 'TOGETHER': 4866, 'TRUMP': 4867, 'Taking': 4868, 'Texas': 4869, 'TheCounterpointer': 4870, 'Them': 4871, 'Thomas': 4872, 'Thorpe': 4873, 'Thought': 4874, 'Three': 4875, 'Through': 4876, 'Thus': 4877, 'Tian': 4878, 'Top': 4879, 'Trader': 4880, 'Tran': 4881, 'Truly': 4882, 'Trust': 4883, 'Tunstall': 4884, 'Turkey': 4885, 'U.S': 4886, 'Ugh': 4887, 'Uh': 4888, 'Ultimate': 4889, 'Ultra': 4890, 'Unbelievable': 4891, 'Unlike': 4892, 'Ur': 4893, 'Use': 4894, 'Usually': 4895, 'Utter': 4896, 'Uzokwe': 4897, 'Valley': 4898, 'Veronica': 4899, 'Victory': 4900, 'Vigorito': 4901, 'Vote': 4902, 'Vujovic': 4903, 'WHEN': 4904, 'WLM': 4905, 'WORD': 4906, 'WRONG': 4907, 'Wade': 4908, 'Whole': 4909, 'Wikipedia': 4910, 'Wilson': 4911, 'Winchester': 4912, 'Windsor': 4913, 'YEARS': 4914, 'YT': 4915, 'Yall': 4916, 'Yusuf': 4917, 'Zimbabwe': 4918, 'abiding': 4919, 'abilities': 4920, 'ability': 4921, 'abomination': 4922, 'ace': 4923, 'achievements': 4924, 'acted': 4925, 'actor': 4926, 'addicts': 4927, 'admirable': 4928, 'admitted': 4929, 'adore': 4930, 'aerospace': 4931, 'affect': 4932, 'affects': 4933, 'agent': 4934, 'aggression': 4935, 'aging': 4936, 'agreement': 4937, 'aids': 4938, 'alllivesmatter': 4939, 'amusing': 4940, 'anarchist': 4941, 'angels': 4942, 'anthem': 4943, 'apartheid': 4944, 'apologise': 4945, 'applying': 4946, 'appropriate': 4947, 'army': 4948, 'arse': 4949, 'artifacts': 4950, 'assistance': 4951, 'associated': 4952, 'attacks': 4953, 'autistic': 4954, 'available': 4955, 'aw': 4956, 'awarded': 4957, 'backs': 4958, 'bacon': 4959, 'bag': 4960, 'ball': 4961, 'band': 4962, 'bat': 4963, 'battery': 4964, 'bean': 4965, 'beats': 4966, 'beg': 4967, 'believer': 4968, 'belive': 4969, 'bell': 4970, 'beloved': 4971, 'bent': 4972, 'bigots': 4973, 'bills': 4974, 'bio': 4975, 'biologically': 4976, 'bitter': 4977, 'blatant': 4978, 'blks': 4979, 'boat': 4980, 'boi': 4981, 'bollocks': 4982, 'boring': 4983, 'bow': 4984, 'boxes': 4985, 'boyfriend': 4986, 'brainwash': 4987, 'bully': 4988, 'burger': 4989, 'butthurt': 4990, 'carefully': 4991, 'carrying': 4992, 'casting': 4993, 'cats': 4994, 'celebrity': 4995, 'celebs': 4996, 'cells': 4997, 'chants': 4998, 'characters': 4999, 'cheap': 5000, 'chemistry': 5001, 'cherry': 5002, 'chief': 5003, 'clarify': 5004, 'classmates': 5005, 'click': 5006, 'climate': 5007, 'code': 5008, 'collective': 5009, 'colonies': 5010, 'colubrum': 5011, 'commandment': 5012, 'comming': 5013, 'compassion': 5014, 'complaint': 5015, 'complexion': 5016, 'complicated': 5017, 'conducted': 5018, 'confirm': 5019, 'confusing': 5020, 'confusion': 5021, 'conquered': 5022, 'continues': 5023, 'continuing': 5024, 'conversations': 5025, 'convert': 5026, 'converted': 5027, 'conviction': 5028, 'core': 5029, 'counting': 5030, 'cousins': 5031, 'coverage': 5032, 'covered': 5033, 'covers': 5034, 'cringe': 5035, 'critical': 5036, 'criticism': 5037, 'criticize': 5038, 'criticizing': 5039, 'cruel': 5040, 'crushed': 5041, 'cuffs': 5042, 'dates': 5043, 'deadly': 5044, 'deals': 5045, 'debating': 5046, 'debunked': 5047, 'decade': 5048, 'deception': 5049, 'default': 5050, 'dem': 5051, 'demographic': 5052, 'demolish': 5053, 'depression': 5054, 'descendants': 5055, 'destroys': 5056, 'detail': 5057, 'details': 5058, 'determination': 5059, 'determined': 5060, 'developer': 5061, 'disabled': 5062, 'discussed': 5063, 'disgusted': 5064, 'disorder': 5065, 'disprove': 5066, 'disrespect': 5067, 'distance': 5068, 'distracting': 5069, 'disturbing': 5070, 'documentary': 5071, 'dole': 5072, 'dollar': 5073, 'donÂ´t': 5074, 'downs': 5075, 'drawings': 5076, 'drink': 5077, 'drops': 5078, 'drunk': 5079, 'duh': 5080, 'earned': 5081, 'effort': 5082, 'efforts': 5083, 'elementary': 5084, 'embarrassing': 5085, 'empower': 5086, 'empowering': 5087, 'enabled': 5088, 'encounter': 5089, 'encourage': 5090, 'entitlement': 5091, 'environmental': 5092, 'epidemic': 5093, 'equation': 5094, 'erasing': 5095, 'erected': 5096, 'eternity': 5097, 'europe': 5098, 'evolved': 5099, 'excludes': 5100, 'excuses': 5101, 'executed': 5102, 'expose': 5103, 'exposing': 5104, 'extent': 5105, 'factor': 5106, 'fairness': 5107, 'fallacy': 5108, 'fans': 5109, 'fascinating': 5110, 'fascists': 5111, 'fashionable': 5112, 'favour': 5113, 'favourite': 5114, 'figured': 5115, 'fill': 5116, 'filter': 5117, 'final': 5118, 'finding': 5119, 'finished': 5120, 'fires': 5121, 'firm': 5122, 'floor': 5123, 'fooling': 5124, 'fortnite': 5125, 'founders': 5126, 'founding': 5127, 'freaks': 5128, 'fucktard': 5129, 'fueled': 5130, 'fundamental': 5131, 'fuss': 5132, 'gangster': 5133, 'gangsters': 5134, 'garden': 5135, 'gathering': 5136, 'gee': 5137, 'generalizing': 5138, 'genius': 5139, 'germany': 5140, 'globalist': 5141, 'glorify': 5142, 'goofy': 5143, 'google': 5144, 'graduating': 5145, 'grammar': 5146, 'grandfather': 5147, 'granny': 5148, 'grills': 5149, 'guard': 5150, 'guilt': 5151, 'hairstyle': 5152, 'handful': 5153, 'handsome': 5154, 'hanging': 5155, 'happily': 5156, 'healthcare': 5157, 'heartless': 5158, 'hello': 5159, 'hers': 5160, 'historically': 5161, 'hmm': 5162, 'holes': 5163, 'holiday': 5164, 'honesty': 5165, 'honour': 5166, 'horrendous': 5167, 'horrific': 5168, 'horse': 5169, 'hung': 5170, 'idc': 5171, 'identifies': 5172, 'ig': 5173, 'illogical': 5174, 'imply': 5175, 'implying': 5176, 'inappropriate': 5177, 'increased': 5178, 'indirectly': 5179, 'inferior': 5180, 'inherently': 5181, 'inherit': 5182, 'insist': 5183, 'instagram': 5184, 'intended': 5185, 'interrupting': 5186, 'intro': 5187, 'invited': 5188, 'island': 5189, 'james': 5190, 'judgemental': 5191, 'justifying': 5192, 'kindness': 5193, 'kiss': 5194, 'kitchen': 5195, 'kitty': 5196, 'kneeling': 5197, 'lacking': 5198, 'largely': 5199, 'largest': 5200, 'larry': 5201, 'laundering': 5202, 'legally': 5203, 'legitimately': 5204, 'lego': 5205, 'letters': 5206, 'lgbt+': 5207, 'libs': 5208, 'lift': 5209, 'linked': 5210, 'links': 5211, 'm8': 5212, 'ma': 5213, 'martyr': 5214, 'match': 5215, 'mattter': 5216, 'mdna': 5217, 'medical': 5218, 'melted': 5219, 'memories': 5220, 'memory': 5221, 'mercy': 5222, 'mike': 5223, 'minister': 5224, 'models': 5225, 'museums': 5226, 'myth': 5227, 'nTo': 5228, 'named': 5229, 'narrow': 5230, 'nd': 5231, 'nerds': 5232, 'niece': 5233, 'nnAll': 5234, 'normally': 5235, 'nowadays': 5236, 'nursing': 5237, 'nut': 5238, 'obsessed': 5239, 'oil': 5240, 'oneself': 5241, 'oops': 5242, 'opposed': 5243, 'ordered': 5244, 'origin': 5245, 'originally': 5246, 'origins': 5247, 'ounce': 5248, 'ours': 5249, 'owe': 5250, 'owns': 5251, 'p': 5252, 'pagan': 5253, 'painted': 5254, 'partly': 5255, 'passage': 5256, 'pause': 5257, 'payer': 5258, 'pea': 5259, 'percentage': 5260, 'permission': 5261, 'persecuted': 5262, 'perspectives': 5263, 'petty': 5264, 'phones': 5265, 'plans': 5266, 'plantations': 5267, 'poland': 5268, 'pose': 5269, 'powerless': 5270, 'praise': 5271, 'praised': 5272, 'precisely': 5273, 'presence': 5274, 'press': 5275, 'priests': 5276, 'prior': 5277, 'prisoners': 5278, 'profitable': 5279, 'project': 5280, 'promoting': 5281, 'propose': 5282, 'prosecuted': 5283, 'protested': 5284, 'protester': 5285, 'providing': 5286, 'purely': 5287, 'purposes': 5288, 'quoted': 5289, 'raising': 5290, 'rarely': 5291, 'rational': 5292, 'reached': 5293, 'react': 5294, 'reasoning': 5295, 'rebuild': 5296, 'reflection': 5297, 'regularly': 5298, 'relatable': 5299, 'remain': 5300, 'remains': 5301, 'repair': 5302, 'repeated': 5303, 'repeats': 5304, 'replaced': 5305, 'replies': 5306, 'reporter': 5307, 'reporting': 5308, 'representation': 5309, 'represents': 5310, 'require': 5311, 'responses': 5312, 'riddance': 5313, 'rite': 5314, 'road': 5315, 'robbery': 5316, 'robbing': 5317, 'rock': 5318, 'rocks': 5319, 'rolling': 5320, 'roost': 5321, 'round': 5322, 'rubbish': 5323, 'ruins': 5324, 'ruling': 5325, 'sacrifice': 5326, 'scanlon': 5327, 'scheme': 5328, 'screwed': 5329, 'scum': 5330, 'secretary': 5331, 'sections': 5332, 'series': 5333, 'serve': 5334, 'sexes': 5335, 'sexualities': 5336, 'shed': 5337, 'shift': 5338, 'shine': 5339, 'shits': 5340, 'shoot-': 5341, 'shoots': 5342, 'shoud': 5343, 'sickening': 5344, 'sigh': 5345, 'sinned': 5346, 'slander': 5347, 'slaver': 5348, 'slight': 5349, 'slightly': 5350, 'slowly': 5351, 'smoke': 5352, 'societies': 5353, 'sola': 5354, 'solving': 5355, 'someday': 5356, 'someones': 5357, 'sophomore': 5358, 'soros': 5359, 'sounded': 5360, 'specially': 5361, 'spectrum': 5362, 'speeches': 5363, 'spinning': 5364, 'station': 5365, 'stays': 5366, 'steal': 5367, 'stir': 5368, 'stock': 5369, 'stones': 5370, 'strike': 5371, 'subs': 5372, 'subscribers': 5373, 'substance': 5374, 'suffers': 5375, 'supply': 5376, 'supposedly': 5377, 'surely': 5378, 'suspect': 5379, 'sweetie': 5380, 'symbols': 5381, 'sympathy': 5382, 'talent': 5383, 'task': 5384, 'teared': 5385, 'ted': 5386, 'teens': 5387, 'theDargon': 5388, 'thirteen': 5389, 'thousand': 5390, 'threatening': 5391, 'tolerate': 5392, 'tongue': 5393, 'torturing': 5394, 'touched': 5395, 'tourr': 5396, 'tours': 5397, 'track': 5398, 'traded': 5399, 'trades': 5400, 'translation': 5401, 'travel': 5402, 'tribal': 5403, 'trick': 5404, 'troops': 5405, 'truest': 5406, 'tube': 5407, 'turtle': 5408, 'twats': 5409, 'typed': 5410, 'typically': 5411, 'ultimate': 5412, 'un': 5413, 'undervalued': 5414, 'untill': 5415, 'upbringing': 5416, 'update': 5417, 'ups': 5418, 'utopia': 5419, 'utter': 5420, 'v': 5421, 'vegan': 5422, 'vice': 5423, 'voices': 5424, 'w/': 5425, 'wagon': 5426, 'warped': 5427, 'washed': 5428, 'wasting': 5429, 'wealthy': 5430, 'weapon': 5431, 'web': 5432, 'whip': 5433, 'whoever': 5434, 'willholt11': 5435, 'window': 5436, 'windows': 5437, 'wings': 5438, 'worlds': 5439, 'worries': 5440, 'wrinkles': 5441, 'writer': 5442, 'wrongs': 5443, 'ye': 5444, 'yesss': 5445, 'yup': 5446, '|': 5447, '\\xa0\\xa0': 5448, 'Â«': 5449, 'Â»': 5450, 'ðŸ¤Ÿ': 5451, 'ðŸ¤¯': 5452})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN4ZXxA1eYl2",
        "outputId": "9af377d1-9bde-4d6d-a1d6-7c69f134537a"
      },
      "source": [
        "# check whether cuda is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "# Load an iterator\n",
        "#train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits((train_data, valid_data, test_data),batch_size=BATCH_SIZE, sort_key=lambda x: len(x.text),sort_within_batch=True,device=device)\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits((train_data, valid_data),batch_size=BATCH_SIZE, sort_key=lambda x: len(x.text),sort_within_batch=True,device=device)\n",
        "\n",
        "\n",
        "# define hyperparameters\n",
        "size_of_vocab = len(TEXT.vocab)\n",
        "print(size_of_vocab)\n",
        "embedding_dim = 100\n",
        "num_hidden_nodes = 128\n",
        "num_output_nodes = 1\n",
        "num_layers = 2\n",
        "bidirection = True\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "  #\n",
        "# # instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers,\n",
        "                      bidirectional=True, dropout=dropout, pad_idx=PAD_IDX)\n",
        "print(model)\n",
        "\n",
        "\n",
        "# No. of trianable parameters\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "5453\n",
            "classifier(\n",
            "  (embedding): Embedding(5453, 100, padding_idx=1)\n",
            "  (lstm): LSTM(100, 128, num_layers=2, dropout=0.5, bidirectional=True)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (act): Sigmoid()\n",
            ")\n",
            "The model has 1,176,341 trainable parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8Tadd40egS9",
        "outputId": "3fa0b420-661c-4ab3-abdb-f8441a4bc013"
      },
      "source": [
        "\n",
        "# Initialize the pretrained embedding\n",
        "pretrained_embeddings = TEXT.vocab.vectors #replaces the initial weights of embedding later with the pre-trained embeddings\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "print(pretrained_embeddings.shape)\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(embedding_dim)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(embedding_dim)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5453, 100])\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.3398,  0.2094,  0.4635,  ..., -0.2339,  0.4730, -0.0288],\n",
            "        ...,\n",
            "        [ 0.0587,  0.0901, -0.0142,  ..., -0.1028,  0.0044, -0.2619],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBm-GivbkfkQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c62955e2-cfbb-4a3e-d5a8-d2c3ded5008d"
      },
      "source": [
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# push to cuda if available\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('device:', device)\n",
        "\n",
        "model.cuda()\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "\n",
        "print('cuda parmaters:', next(model.parameters()).is_cuda)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "val_loss_vector = []\n",
        "val_acc_vector = []\n",
        "train_loss_vector = []\n",
        "train_acc_vector = []"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n",
            "cuda parmaters: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaCkX86ycvrO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "873f5212-2026-4b22-f164-9ffd7e5ab39c"
      },
      "source": [
        "\n",
        "for epoch in range(20):\n",
        "    print(\"Epoch: \", epoch)\n",
        "\n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, train_loss_vector, train_acc_vector, criterion)\n",
        "\n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(epoch, model, valid_iterator, val_loss_vector, val_acc_vector, criterion)\n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        #torch.save(model.state_dict(), 'lstm.pt')\n",
        "\n",
        "\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.2f}%')\n",
        "\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
        "\n",
        "\n",
        "print(val_loss_vector)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t Val. Loss: 0.230 |  Val. Acc: 91.32%\n",
            "\tTrain Loss: 0.288 | Train Acc: 91.01%\n",
            "Epoch:  1\n",
            "\t Val. Loss: 0.209 |  Val. Acc: 92.23%\n",
            "\tTrain Loss: 0.212 | Train Acc: 91.95%\n",
            "Epoch:  2\n",
            "\t Val. Loss: 0.208 |  Val. Acc: 92.62%\n",
            "\tTrain Loss: 0.179 | Train Acc: 93.30%\n",
            "Epoch:  3\n",
            "\t Val. Loss: 0.214 |  Val. Acc: 92.34%\n",
            "\tTrain Loss: 0.149 | Train Acc: 94.39%\n",
            "Epoch:  4\n",
            "\t Val. Loss: 0.245 |  Val. Acc: 92.40%\n",
            "\tTrain Loss: 0.126 | Train Acc: 95.28%\n",
            "Epoch:  5\n",
            "\t Val. Loss: 0.240 |  Val. Acc: 91.97%\n",
            "\tTrain Loss: 0.104 | Train Acc: 96.18%\n",
            "Epoch:  6\n",
            "\t Val. Loss: 0.249 |  Val. Acc: 92.21%\n",
            "\tTrain Loss: 0.089 | Train Acc: 96.69%\n",
            "Epoch:  7\n",
            "\t Val. Loss: 0.369 |  Val. Acc: 91.12%\n",
            "\tTrain Loss: 0.076 | Train Acc: 97.17%\n",
            "Epoch:  8\n",
            "\t Val. Loss: 0.375 |  Val. Acc: 92.06%\n",
            "\tTrain Loss: 0.063 | Train Acc: 97.62%\n",
            "Epoch:  9\n",
            "\t Val. Loss: 0.431 |  Val. Acc: 90.69%\n",
            "\tTrain Loss: 0.050 | Train Acc: 98.12%\n",
            "Epoch:  10\n",
            "\t Val. Loss: 0.571 |  Val. Acc: 90.06%\n",
            "\tTrain Loss: 0.044 | Train Acc: 98.17%\n",
            "Epoch:  11\n",
            "\t Val. Loss: 0.569 |  Val. Acc: 91.19%\n",
            "\tTrain Loss: 0.026 | Train Acc: 98.49%\n",
            "Epoch:  12\n",
            "\t Val. Loss: 0.360 |  Val. Acc: 90.39%\n",
            "\tTrain Loss: 0.014 | Train Acc: 98.36%\n",
            "Epoch:  13\n",
            "\t Val. Loss: 0.612 |  Val. Acc: 90.32%\n",
            "\tTrain Loss: 0.009 | Train Acc: 98.76%\n",
            "Epoch:  14\n",
            "\t Val. Loss: 0.602 |  Val. Acc: 90.65%\n",
            "\tTrain Loss: -0.021 | Train Acc: 98.85%\n",
            "Epoch:  15\n",
            "\t Val. Loss: 0.674 |  Val. Acc: 90.69%\n",
            "\tTrain Loss: -0.030 | Train Acc: 99.11%\n",
            "Epoch:  16\n",
            "\t Val. Loss: 0.828 |  Val. Acc: 88.17%\n",
            "\tTrain Loss: -0.047 | Train Acc: 99.21%\n",
            "Epoch:  17\n",
            "\t Val. Loss: 0.860 |  Val. Acc: 91.21%\n",
            "\tTrain Loss: -0.047 | Train Acc: 99.16%\n",
            "Epoch:  18\n",
            "\t Val. Loss: 0.919 |  Val. Acc: 89.95%\n",
            "\tTrain Loss: -0.055 | Train Acc: 99.28%\n",
            "Epoch:  19\n",
            "\t Val. Loss: 0.856 |  Val. Acc: 90.80%\n",
            "\tTrain Loss: -0.041 | Train Acc: 99.31%\n",
            "[16.55687517672777, 15.024116076529026, 14.95453792437911, 15.437333522364497, 17.625987695530057, 17.276439178735018, 17.89661603420973, 26.591541254892945, 26.97613580431789, 31.012683141976595, 41.131430100649595, 40.941717095673084, 25.92508528009057, 44.0641484297812, 43.37399523705244, 48.5255038626492, 59.621868677437305, 61.92189074866474, 66.19825986400247, 61.64297430217266]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykUd6OMK9tmj"
      },
      "source": [
        "def f1_loss(y_pred:torch.Tensor, y_true:torch.Tensor, is_training=False):\n",
        "    '''Calculate F1 score. Can work with gpu tensors'''\n",
        "   \n",
        "    assert y_true.ndim == 1\n",
        "    assert y_pred.ndim == 1 or y_pred.ndim == 2\n",
        "    \n",
        "    if y_pred.ndim == 2:\n",
        "        y_pred = y_pred.argmax(dim=1)\n",
        "    \n",
        "    y_pred = torch.round(torch.sigmoid(y_pred))\n",
        "   \n",
        "   \n",
        "\n",
        "    \n",
        "    tp = (y_true * y_pred).sum().to(torch.float32)\n",
        "    tn = ((1 - y_true) * (1 - y_pred)).sum().to(torch.float32)\n",
        "    fp = ((1 - y_true) * y_pred).sum().to(torch.float32)\n",
        "    fn = (y_true * (1 - y_pred)).sum().to(torch.float32)\n",
        "    \n",
        "    epsilon = 1e-7\n",
        "    \n",
        "    precision = tp / (tp + fp + epsilon)\n",
        "    recall = tp / (tp + fn + epsilon)\n",
        "    \n",
        "    f1 = 2* (precision*recall) / (precision + recall + epsilon)\n",
        "    f1.requires_grad = is_training\n",
        "    return f1, precision, recall, tp, tn, fp, fn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVZilGeoQUOa",
        "outputId": "6a78aeee-df78-4828-b4ec-3556b87a413d"
      },
      "source": [
        "unseen_data_2 = data.TabularDataset(path=\"/content/drive/MyDrive/Hope_Dataset/test.tsv\",format='tsv', fields= [('text', TEXT), ('label', LABEL)], skip_header=True)\n",
        "\n",
        "unseen_train_data, unseen_data = unseen_data_2.split(split_ratio=0.99,\n",
        "                                                      random_state=random.seed(\n",
        "                                                          SEED)) \n",
        "\n",
        "print(len(unseen_train_data))\n",
        "print(len(unseen_data))\n",
        "\n",
        "LABEL.build_vocab(unseen_train_data)\n",
        "unseen_train_data_iter, unseen_data_iter = data.BucketIterator.splits((unseen_train_data, unseen_data),\n",
        "                                                                        batch_size=256,\n",
        "                                                                        sort_key=lambda x: len(x.text),\n",
        "                                                                        sort_within_batch=True, device=device)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2815\n",
            "28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slTSlPxdFdmv"
      },
      "source": [
        "def evaluate_testset(model, unseen_train_data_iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    tp_total = 0\n",
        "    tn_total = 0 \n",
        "    fp_total = 0\n",
        "    fn_total =0\n",
        "    total_no_inputs = 0\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in unseen_train_data_iter:\n",
        "            #print('batch:', batch)\n",
        "            total_no_inputs += 256\n",
        "            #print(total_no_inputs)\n",
        "\n",
        "            text, text_lengths = batch.text\n",
        "\n",
        "        \n",
        "            predictions = model(text, text_lengths).squeeze()\n",
        "            #predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            #print('label:', batch.label)\n",
        "            #print('preds;', predictions)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            f1, precision, recall, tp, tn, fp, fn= f1_loss(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            tp_total +=tp.item()\n",
        "            fp_total +=fp.item()\n",
        "            tn_total +=tn.item()\n",
        "            fn_total +=fn.item()\n",
        "           \n",
        "\n",
        "    return epoch_loss / len(unseen_train_data_iter), epoch_acc / len(unseen_train_data_iter), tp_total, tn_total, fp_total, fn_total \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YQiAKwiFrR3",
        "outputId": "11a40d91-7143-4217-9543-11c5a994c495"
      },
      "source": [
        "\n",
        "unseen_test_loss, unseen_test_acc, tp_total, tn_total, fp_total, fn_total = evaluate_testset(model, unseen_train_data_iter, criterion)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNZsXM2fN3mc",
        "outputId": "644daabf-93c3-458d-a747-005a6e8465d9"
      },
      "source": [
        "print(f'Unseen Test Loss: {unseen_test_loss:.3f} | Unseen Test Acc: {unseen_test_acc * 100:.2f}%')\n",
        "print(  'tp:', tp_total, 'tn:', tn_total, 'fp:', fp_total, 'fn:', fn_total)\n",
        "prec = tp_total/(tp_total + fp_total)\n",
        "recall = tp_total/(tp_total + fn_total)\n",
        "print('Recall', recall)\n",
        "print('Prec', prec )\n",
        "\n",
        "print(\"finished\")   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unseen Test Loss: 1.589 | Unseen Test Acc: 85.22%\n",
            "tp: 142.0 tn: 966.0 fp: 1612.0 fn: 95.0\n",
            "Recall 0.5991561181434599\n",
            "Prec 0.08095781071835804\n",
            "finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVRH1e5GQKHq",
        "outputId": "bfcadbd3-e3c1-4b2d-9514-84d65c85d5b8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6uZ0hwASn7V"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "jhWLfeESSrdY",
        "outputId": "ee23a359-c6b7-4bdb-b5cd-ac849ca81664"
      },
      "source": [
        "df2 = pd.read_csv(\"/content/drive/MyDrive/Tweets.csv\",encoding='latin1')\n",
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 487
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "a60Vb7BdSraQ",
        "outputId": "21730c9b-a78b-4693-b415-fbd09709f2e6"
      },
      "source": [
        "#Training datset\n",
        "\n",
        "df2[\"airline_sentiment\"] = df2[\"airline_sentiment\"].replace(\"neutral\", \"negative\")\n",
        "df2=df2[[\"text\",\"airline_sentiment\"]]\n",
        "df2.columns = ['text', 'label']\n",
        "df2.sample(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4249</th>\n",
              "      <td>@united giving up on your direct flight from I...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13429</th>\n",
              "      <td>@AmericanAir tisk tisk. Rude flight attendants...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3675</th>\n",
              "      <td>@united, I'm still frustrated I gave up my sea...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4396</th>\n",
              "      <td>You have to follow me back so that I can DM @S...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10081</th>\n",
              "      <td>@USAirways flight 1735 sitting fully loaded fo...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5081</th>\n",
              "      <td>@SouthwestAir yall have me sleeping in the air...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3604</th>\n",
              "      <td>@united thanks</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2950</th>\n",
              "      <td>@united can't wait!!! 787!!! @tpallini http://...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14607</th>\n",
              "      <td>@AmericanAir i need someone to help me out</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10531</th>\n",
              "      <td>@USAirways now what? You Cancelled Flightled m...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text     label\n",
              "4249   @united giving up on your direct flight from I...  negative\n",
              "13429  @AmericanAir tisk tisk. Rude flight attendants...  negative\n",
              "3675   @united, I'm still frustrated I gave up my sea...  negative\n",
              "4396   You have to follow me back so that I can DM @S...  negative\n",
              "10081  @USAirways flight 1735 sitting fully loaded fo...  negative\n",
              "5081   @SouthwestAir yall have me sleeping in the air...  negative\n",
              "3604                                      @united thanks  positive\n",
              "2950   @united can't wait!!! 787!!! @tpallini http://...  positive\n",
              "14607         @AmericanAir i need someone to help me out  negative\n",
              "10531  @USAirways now what? You Cancelled Flightled m...  negative"
            ]
          },
          "metadata": {},
          "execution_count": 488
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrvKdb3sSrXJ"
      },
      "source": [
        "df2.to_csv('/content/drive/MyDrive/AirlineTweet.tsv', sep=\"\\t\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m__QXd5KSrUC",
        "outputId": "47b6c857-ba3a-4768-a9c2-a3bdd2d210f8"
      },
      "source": [
        "unseen_data2 = data.TabularDataset(path=\"/content/drive/MyDrive/AirlineTweet.tsv\",format='tsv', fields = [('text', TEXT), ('label', LABEL)], skip_header=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX4W7A9zSrQo",
        "outputId": "15705274-a501-44d3-cc94-48a935fc3abf"
      },
      "source": [
        "print(df2['label'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative    12277\n",
            "positive     2363\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG4EeAzvSrMv",
        "outputId": "0e2bbf5c-c064-4aa4-ce31-fcd87665a5ec"
      },
      "source": [
        "\n",
        "unseen_train_data, unseen_data = unseen_data2.split(split_ratio=0.99,\n",
        "                                                      random_state=random.seed(\n",
        "                                                          SEED)) \n",
        "\n",
        "print(len(unseen_train_data))\n",
        "print(len(unseen_data))\n",
        "\n",
        "LABEL.build_vocab(unseen_train_data)\n",
        "unseen_train_data_iter, unseen_data_iter = data.BucketIterator.splits((unseen_train_data, unseen_data),\n",
        "                                                                        batch_size=256,\n",
        "                                                                        sort_key=lambda x: len(x.text),\n",
        "                                                                        sort_within_batch=True, device=device)\n",
        "                                                                  \n",
        "\n",
        "unseen_test_loss, unseen_test_acc, tp_total, tn_total, fp_total, fn_total = evaluate_testset(model, unseen_train_data_iter, criterion)\n",
        "print(f'Unseen Test Loss: {unseen_test_loss:.3f} | Unseen Test Acc: {unseen_test_acc * 100:.2f}%')\n",
        "print(  'tp:', tp_total, 'tn:', tn_total, 'fp:', fp_total, 'fn:', fn_total)\n",
        "prec = tp_total/(tp_total + fp_total)\n",
        "recall = tp_total/(tp_total + fn_total)\n",
        "print('Recall', recall)\n",
        "print('Prec', prec )\n",
        "F1 = 2*prec*recall/ (prec+recall)\n",
        "print('F1:', F1)\n",
        "print(\"finished\")   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14494\n",
            "146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unseen Test Loss: 1.888 | Unseen Test Acc: 81.90%\n",
            "tp: 1967.0 tn: 1911.0 fp: 10236.0 fn: 380.0\n",
            "Recall 0.838091180230081\n",
            "Prec 0.16118987134311236\n",
            "F1: 0.27037800687285224\n",
            "finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nge8yQMWSrJk",
        "outputId": "381ea08b-fe83-4ae9-feb3-a863a5c94614"
      },
      "source": [
        "df3 = pd.read_csv(\"/content/drive/MyDrive/coviddataset.csv\",encoding='latin1')\n",
        "df3.dropna(subset = [\"Sentiment\"], inplace=True)\n",
        "df3.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3799</td>\n",
              "      <td>48751</td>\n",
              "      <td>London</td>\n",
              "      <td>16/03/2020</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3800</td>\n",
              "      <td>48752</td>\n",
              "      <td>UK</td>\n",
              "      <td>16/03/2020</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3801</td>\n",
              "      <td>48753</td>\n",
              "      <td>Vagabonds</td>\n",
              "      <td>16/03/2020</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3802</td>\n",
              "      <td>48754</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16/03/2020</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3803</td>\n",
              "      <td>48755</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16/03/2020</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UserName  ...           Sentiment\n",
              "0      3799  ...             Neutral\n",
              "1      3800  ...            Positive\n",
              "2      3801  ...            Positive\n",
              "3      3802  ...            Positive\n",
              "4      3803  ...  Extremely Negative\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 493
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "F1xpUcMeSrGc",
        "outputId": "776e918c-2817-4b5a-d336-c9ba52984301"
      },
      "source": [
        "df3['Sentiment'] = df3['Sentiment'].map({'Positive':'negative', 'Extremely Positive':\"positive\",'Negative':\"negative\",'Extremely Negative':\"negative\",'Neutral':\"negative\"})\n",
        "df3=df3[[\"OriginalTweet\",\"Sentiment\"]]\n",
        "df3.columns = ['text', 'label']\n",
        "df3.sample(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2439</th>\n",
              "      <td>Any news on mortgage companies, car finance or...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3947</th>\n",
              "      <td>Music to listen to on your next trip to the gr...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1643</th>\n",
              "      <td>At the local grocery store now and almost all ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7254</th>\n",
              "      <td>Experts can discuss how #coronavirus is likely...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1707</th>\n",
              "      <td>(TAKE3) High time PM @ScottMorrisonMP sat down...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510</th>\n",
              "      <td>We have enough food, assures PM\\n\\nhttps://t.c...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7349</th>\n",
              "      <td>Please be smart and prepare. Here my take Â“Sto...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2652</th>\n",
              "      <td>IKEA closing all U S stores due to COVID 19 wi...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6987</th>\n",
              "      <td>People be embarrassed to wear masks glasses am...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6408</th>\n",
              "      <td>@ThabitSenior @mpoki_m @msangijeff @danielmarr...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text     label\n",
              "2439  Any news on mortgage companies, car finance or...  negative\n",
              "3947  Music to listen to on your next trip to the gr...  negative\n",
              "1643  At the local grocery store now and almost all ...  negative\n",
              "7254  Experts can discuss how #coronavirus is likely...  negative\n",
              "1707  (TAKE3) High time PM @ScottMorrisonMP sat down...  negative\n",
              "510   We have enough food, assures PM\\n\\nhttps://t.c...  negative\n",
              "7349  Please be smart and prepare. Here my take Â“Sto...  positive\n",
              "2652  IKEA closing all U S stores due to COVID 19 wi...  negative\n",
              "6987  People be embarrassed to wear masks glasses am...  negative\n",
              "6408  @ThabitSenior @mpoki_m @msangijeff @danielmarr...  negative"
            ]
          },
          "metadata": {},
          "execution_count": 494
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSlXwPmpSrC1"
      },
      "source": [
        "df3.to_csv('/content/drive/MyDrive/covid_test.tsv', sep=\"\\t\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6CN5u_ISq_J",
        "outputId": "58103843-acac-422e-de73-bc5e7033199b"
      },
      "source": [
        "unseen_data3 = data.TabularDataset(path=\"/content/drive/MyDrive/covid_test.tsv\",format='tsv', fields=[('text', TEXT), ('label', LABEL)], skip_header=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrQacetVSq7F",
        "outputId": "0af5c84e-7b9e-4598-f306-d5162f29f8a2"
      },
      "source": [
        "print(df3['label'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative    6842\n",
            "positive    1212\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuQWq9HXSq21",
        "outputId": "a650668b-ea56-471f-afcb-ede9b854eccc"
      },
      "source": [
        "unseen_train_data, unseen_data = unseen_data3.split(split_ratio=0.99,\n",
        "                                                      random_state=random.seed(\n",
        "                                                          SEED)) \n",
        "\n",
        "\n",
        "print(len(unseen_train_data))\n",
        "print(len(unseen_data))\n",
        "\n",
        "LABEL.build_vocab(unseen_train_data)\n",
        "unseen_train_data_iter, unseen_data_iter = data.BucketIterator.splits((unseen_train_data, unseen_data),\n",
        "                                                                        batch_size=256,\n",
        "                                                                        sort_key=lambda x: len(x.text),\n",
        "                                                                        sort_within_batch=True, device=device)\n",
        "                                                                  \n",
        "\n",
        "\n",
        "unseen_test_loss, unseen_test_acc, tp_total, tn_total, fp_total, fn_total = evaluate_testset(model, unseen_train_data_iter, criterion)\n",
        "print(f'Unseen Test Loss: {unseen_test_loss:.3f} | Unseen Test Acc: {unseen_test_acc * 100:.2f}%')\n",
        "print(  'tp:', tp_total, 'tn:', tn_total, 'fp:', fp_total, 'fn:', fn_total)\n",
        "prec = tp_total/(tp_total + fp_total)\n",
        "recall = tp_total/(tp_total + fn_total)\n",
        "print('Recall', recall)\n",
        "print('Prec', prec )\n",
        "F1 = 2*prec*recall/ (prec+recall)\n",
        "print('F1:', F1)\n",
        "print(\"finished\")   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7973\n",
            "81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unseen Test Loss: 1.562 | Unseen Test Acc: 82.70%\n",
            "tp: 1092.0 tn: 1063.0 fp: 5705.0 fn: 113.0\n",
            "Recall 0.9062240663900415\n",
            "Prec 0.16065911431513905\n",
            "F1: 0.2729317670582354\n",
            "finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_XZTRRCSqqV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}